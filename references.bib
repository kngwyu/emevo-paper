@misc{jax2018github,
  title = {{{JAX}}: Composable Transformations of {{Python}}+{{NumPy}} Programs},
  author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and {Wanderman-Milne}, Skye and Zhang, Qiao},
  year = {2018}
}

@article{makehamLawMortalityConstruction1860,
  title = {On the {{Law}} of {{Mortality}} and the {{Construction}} of {{Annuity Tables}}},
  author = {Makeham, William Matthew},
  year = {1860},
  month = jan,
  journal = {Journal of the Institute of Actuaries},
  volume = {8},
  number = {6},
  pages = {301--310},
  publisher = {{Cambridge University Press}},
  issn = {2046-1658},
  doi = {10.1017/S204616580000126X},
  urldate = {2023-03-01},
  abstract = {Most writers on the subject of life annuities have had occasion to lament the paucity of tables available for the performance of calculations involving two or more lives. The late Mr. David Jones has done much to supply this deficiency by the publication of complete sets of tables for two lives at various rates of interest; but, beyond this, it is extremely improbable that, under the present system, any considerable progress will be made, owing to the multiplicity of the different combinations when three or more lives are concerned, and the consequent magnitude of the task involved in the construction of complete sets of tables for such cases.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Journal of the Institute of Actuaries1860\\Makeham_1860_On the Law of Mortality and the Construction of Annuity Tables.pdf}
}

@article{kirkwoodDecipheringDeathCommentary2015,
  title = {Deciphering Death: A Commentary on {{Gompertz}} (1825) `{{On}} the Nature of the Function Expressive of the Law of Human Mortality, and on a New Mode of Determining the Value of Life Contingencies'},
  shorttitle = {Deciphering Death},
  author = {Kirkwood, Thomas B. L.},
  year = {2015},
  month = apr,
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {370},
  number = {1666},
  pages = {20140379},
  publisher = {{Royal Society}},
  doi = {10.1098/rstb.2014.0379},
  urldate = {2023-03-01},
  abstract = {In 1825, the actuary Benjamin Gompertz read a paper, `On the nature of the function expressive of the law of human mortality, and on a new mode of determining the value of life contingencies', to the Royal Society in which he showed that over much of the adult human lifespan, age-specific mortality rates increased in an exponential manner. Gompertz's work played an important role in shaping the emerging statistical science that underpins the pricing of life insurance and annuities. Latterly, as the subject of ageing itself became the focus of scientific study, the Gompertz model provided a powerful stimulus to examine the patterns of death across the life course not only in humans but also in a wide range of other organisms. The idea that the Gompertz model might constitute a fundamental `law of mortality' has given way to the recognition that other patterns exist, not only across the species range but also in advanced old age. Nevertheless, Gompertz's way of representing the function expressive of the pattern of much of adult mortality retains considerable relevance for studying the factors that influence the intrinsic biology of ageing. This commentary was written to celebrate the 350th anniversary of the journal Philosophical Transactions of the Royal Society.},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Philosophical Transactions of the Royal Society B Biological Sciences2015\\Kirkwood_2015_Deciphering death.pdf}
}

@article{gompertzXXIVNatureFunction1825,
  title = {{{XXIV}}. {{On}} the Nature of the Function Expressive of the Law of Human Mortality, and on a New Mode of Determining the Value of Life Contingencies. {{In}} a Letter to {{Francis Baily}}, {{Esq}}. {{F}}. {{R}}. {{S}}. \&c},
  author = {Gompertz, Benjamin},
  year = {1825},
  month = jan,
  journal = {Philosophical Transactions of the Royal Society of London},
  volume = {115},
  pages = {513--583},
  publisher = {{Royal Society}},
  doi = {10.1098/rstl.1825.0026},
  urldate = {2023-03-01},
  abstract = {Dear Sir, The frequent opportunities I have had of receiving pleasure from your writings and conversation, have induced me to prefer offering to the Royal Society through your medium, this Paper on Life Contingencies, which forms part of a continuation of my original paper on the same subject, published among the valuable papers of the Society, as by passing through your hands it may receive the advantage of your judgment.},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Philosophical Transactions of the Royal Society of London1997\\Gompertz_1997_XXIV.pdf}
}

@article{richardsFlexibleGrowthFunction1959,
  title = {A {{Flexible Growth Function}} for {{Empirical Use}}},
  author = {Richards, F. J.},
  year = {1959},
  month = jun,
  journal = {Journal of Experimental Botany},
  volume = {10},
  number = {2},
  pages = {290--301},
  issn = {0022-0957},
  doi = {10.1093/jxb/10.2.290},
  urldate = {2023-02-28},
  abstract = {The application of an extended form of von Bertalanffy's growth function to plant data is considered; the equation has considerable flexibility, but is used only to supply an empirical fit. In order to aid the biological analysis of such growth data as are capable of representation by the function, general rate parameters are deduced which are related in a simple manner to its constants.},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Journal of Experimental Botany\\1959\\Richards_1959_A Flexible Growth Function for Empirical Use.pdf}
}

@inproceedings{terryPettingZooGymMultiAgent2021,
  title = {{{PettingZoo}}: {{Gym}} for {{Multi-Agent Reinforcement Learning}}},
  shorttitle = {{{PettingZoo}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Terry, J and Black, Benjamin and Grammel, Nathaniel and Jayakumar, Mario and Hari, Ananth and Sullivan, Ryan and Santos, Luis S and Dieffendahl, Clemens and Horsch, Caroline and {Perez-Vicente}, Rodrigo and Williams, Niall and Lokesh, Yashas and Ravi, Praveen},
  year = {2021},
  volume = {34},
  pages = {15032--15043},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-02-27},
  abstract = {This paper introduces the PettingZoo library and the accompanying Agent Environment Cycle ("AEC") games model. PettingZoo is a library of diverse sets of multi-agent environments with a universal, elegant Python API. PettingZoo was developed with the goal of accelerating research in Multi-Agent Reinforcement Learning ("MARL"), by making work more interchangeable, accessible and reproducible akin to what OpenAI's Gym library did for single-agent reinforcement learning. PettingZoo's API, while inheriting many features of Gym, is unique amongst MARL APIs in that it's based around the novel AEC games model. We argue, in part through case studies on major problems in popular MARL environments, that the popular game models are poor conceptual models of the games commonly used with MARL, that they promote severe bugs that are hard to detect, and that the AEC games model addresses these problems.},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Curran Associates, Inc.2021\\Terry et al_2021_PettingZoo.pdf}
}

@article{brockmanOpenAIGym2016,
  title = {{{OpenAI Gym}}},
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  year = {2016},
  month = jun,
  doi = {10.48550/arXiv.1606.01540},
  urldate = {2023-02-27},
  abstract = {OpenAI Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of OpenAI Gym and the design decisions that went into the software.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\2016\\Brockman et al_2016_OpenAI Gym.pdf}
}

@article{hollandTunicates2016,
  title = {Tunicates},
  author = {Holland, Linda Z.},
  year = {2016},
  month = feb,
  journal = {Current Biology},
  volume = {26},
  number = {4},
  pages = {R146-R152},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2015.12.024},
  urldate = {2023-01-06},
  abstract = {Tunicates, also called urochordates, are an extremely diverse subphylum of the Chordata, a phylum that also contains the vertebrates and cephalochordates. The tunicates seem to have undergone especially rapid evolution: while remaining exclusively marine, they have radiated to occupy habitats ranging from shallow water, to near shore to the open ocean and the deep sea. Furthermore, they have evolved a variety of remarkable reproductive strategies, combining asexual and sexual modes of reproduction that allow for very rapid expansion of populations. An outstanding question is what happened to allow tunicates to evolve so much faster than their nearest relatives, cephalochordates and vertebrates.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Current Biology2016\\Holland_2016_Tunicates.pdf}
}

@article{bredecheEmbodiedEvolutionCollective2018,
  title = {Embodied {{Evolution}} in {{Collective Robotics}}: {{A Review}}},
  shorttitle = {Embodied {{Evolution}} in {{Collective Robotics}}},
  author = {Bredeche, Nicolas and Haasdijk, Evert and Prieto, Abraham},
  year = {2018},
  journal = {Frontiers in Robotics and AI},
  volume = {5},
  issn = {2296-9144},
  urldate = {2023-02-23},
  abstract = {This article provides an overview of evolutionary robotics techniques applied to online distributed evolution for robot collectives, namely, embodied evolution. It provides a definition of embodied evolution as well as a thorough description of the underlying concepts and mechanisms. This article also presents a comprehensive summary of research published in the field since its inception around the year 2000, providing various perspectives to identify the major trends. In particular, we identify a shift from considering embodied evolution as a parallel search method within small robot collectives (fewer than 10 robots) to embodied evolution as an online distributed learning method for designing collective behaviors in swarm-like collectives. This article concludes with a discussion of applications and open questions, providing a milestone for past and an inspiration for future research.},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Frontiers in Robotics and AI2018\\Bredeche et al_2018_Embodied Evolution in Collective Robotics.pdf}
}

@article{uchibeFindingIntrinsicRewards2008,
  title = {Finding Intrinsic Rewards by Embodied Evolution and Constrained Reinforcement Learning},
  author = {Uchibe, Eiji and Doya, Kenji},
  year = {2008},
  month = dec,
  journal = {Neural Networks},
  series = {{{ICONIP}} 2007},
  volume = {21},
  number = {10},
  pages = {1447--1455},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2008.09.013},
  urldate = {2023-02-23},
  abstract = {Understanding the design principle of reward functions is a substantial challenge both in artificial intelligence and neuroscience. Successful acquisition of a task usually requires not only rewards for goals, but also for intermediate states to promote effective exploration. This paper proposes a method for designing `intrinsic' rewards of autonomous agents by combining constrained policy gradient reinforcement learning and embodied evolution. To validate the method, we use Cyber Rodent robots, in which collision avoidance, recharging from battery packs, and `mating' by software reproduction are three major `extrinsic' rewards. We show in hardware experiments that the robots can find appropriate `intrinsic' rewards for the vision of battery packs and other robots to promote approach behaviors.},
  langid = {english}
}

@article{elfwingEmergencePolymorphicMating2014,
  title = {Emergence of {{Polymorphic Mating Strategies}} in {{Robot Colonies}}},
  author = {Elfwing, Stefan and Doya, Kenji},
  year = {2014},
  month = apr,
  journal = {PLOS ONE},
  volume = {9},
  number = {4},
  pages = {e93622},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0093622},
  urldate = {2023-02-23},
  abstract = {Polymorphism has fascinated evolutionary biologists since the time of Darwin. Biologists have observed discrete alternative mating strategies in many different species. In this study, we demonstrate that polymorphic mating strategies can emerge in a colony of hermaphrodite robots. We used a survival and reproduction task where the robots maintained their energy levels by capturing energy sources and physically exchanged genotypes for the reproduction of offspring. The reproductive success was dependent on the individuals' energy levels, which created a natural trade-off between the time invested in maintaining a high energy level and the time invested in attracting mating partners. We performed experiments in environments with different density of energy sources and observed a variety in the mating behavior when a robot could see both an energy source and a potential mating partner. The individuals could be classified into two phenotypes: 1) forager, who always chooses to capture energy sources, and 2) tracker, who keeps track of potential mating partners if its energy level is above a threshold. In four out of the seven highest fitness populations in different environments, we found subpopulations with distinct differences in genotype and in behavioral phenotype. We analyzed the fitnesses of the foragers and the trackers by sampling them from each subpopulation and mixing with different ratios in a population. The fitness curves for the two subpopulations crossed at about 25\% of foragers in the population, showing the evolutionary stability of the polymorphism. In one of those polymorphic populations, the trackers were further split into two subpopulations: (strong trackers) and (weak trackers). Our analyses show that the population consisting of three phenotypes also constituted several stable polymorphic evolutionarily stable states. To our knowledge, our study is the first to demonstrate the emergence of polymorphic evolutionarily stable strategies within a robot evolution framework.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\PLOS ONE2014\\Elfwing_Doya_2014_Emergence of Polymorphic Mating Strategies in Robot Colonies.pdf}
}

@article{elfwingDarwinianEmbodiedEvolution2011a,
  title = {Darwinian Embodied Evolution of the Learning Ability for Survival},
  author = {Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji and Christensen, Henrik I},
  year = {2011},
  month = apr,
  journal = {Adaptive Behavior},
  volume = {19},
  number = {2},
  pages = {101--120},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {1059-7123},
  doi = {10.1177/1059712310397633},
  urldate = {2023-02-23},
  abstract = {In this article we propose a framework for performing embodied evolution with a limited number of robots, by utilizing time-sharing in subpopulations of virtual agents hosted in each robot. Within this framework, we explore the combination of within-generation learning of basic survival behaviors by reinforcement learning, and evolutionary adaptations over the generations of the basic behavior selection policy, the reward functions, and metaparameters for reinforcement learning. We apply a biologically inspired selection scheme, in which there is no explicit communication of the individuals? fitness information. The individuals can only reproduce offspring by mating?a pair-wise exchange of genotypes?and the probability that an individual reproduces offspring in its own subpopulation is dependent on the individual?s ??health,?? that is, energy level, at the mating occasion. We validate the proposed method by comparing it with evolution using standard centralized selection, in simulation, and by transferring the obtained solutions to hardware using two real robots.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Adaptive Behavior2011\\Elfwing et al_2011_Darwinian embodied evolution of the learning ability for survival.pdf}
}

@inproceedings{elfwingBiologicallyInspiredEmbodied2005,
  title = {Biologically Inspired Embodied Evolution of Survival},
  booktitle = {2005 {{IEEE Congress}} on {{Evolutionary Computation}}},
  author = {Elfwing, S. and Uchibe, E. and Doya, K. and Christensen, H.I.},
  year = {2005},
  month = sep,
  volume = {3},
  pages = {2210-2216 Vol. 3},
  issn = {1941-0026},
  doi = {10.1109/CEC.2005.1554969},
  abstract = {Embodied evolution is a methodology for evolutionary robotics that mimics the distributed, asynchronous and autonomous properties of biological evolution. The evaluation, selection and reproduction are carried out by and between the robots, without any need for human intervention. In this paper, we propose a biologically inspired embodied evolution framework, which fully integrates self-preservation, recharging from external batteries in the environment, and self-reproduction, pair-wise exchange of genetic material, into a survival system. The individuals are explicitly evaluated for the performance of the battery capturing task, but also implicitly for the mating task by the fact that an individual that mates frequently has larger probability to spread its gene in the population. We have evaluated our method in simulation experiments and the simulation results show that the solutions obtained by our embodied evolution method were able to optimize the two survival tasks, battery capturing and mating, simultaneously. We have also performed preliminary experiments in hardware, with promising results.}
}

@article{watsonEmbodiedEvolutionDistributing2002,
  title = {Embodied {{Evolution}}: {{Distributing}} an Evolutionary Algorithm in a Population of Robots},
  shorttitle = {Embodied {{Evolution}}},
  author = {Watson, Richard A. and Ficici, Sevan G. and Pollack, Jordan B.},
  year = {2002},
  month = apr,
  journal = {Robotics and Autonomous Systems},
  volume = {39},
  number = {1},
  pages = {1--18},
  issn = {0921-8890},
  doi = {10.1016/S0921-8890(02)00170-7},
  urldate = {2023-02-23},
  abstract = {We introduce Embodied Evolution (EE) as a new methodology for evolutionary robotics (ER). EE uses a population of physical robots that autonomously reproduce with one another while situated in their task environment. This constitutes a fully distributed evolutionary algorithm embodied in physical robots. Several issues identified by researchers in the evolutionary robotics community as problematic for the development of ER are alleviated by the use of a large number of robots being evaluated in parallel. Particularly, EE avoids the pitfalls of the simulate-and-transfer method and allows the speed-up of evaluation time by utilizing parallelism. The more novel features of EE are that the evolutionary algorithm is entirely decentralized, which makes it inherently scalable to large numbers of robots, and that it uses many robots in a shared task environment, which makes it an interesting platform for future work in collective robotics and Artificial Life. We have built a population of eight robots and successfully implemented the first example of Embodied Evolution by designing a fully decentralized, asynchronous evolutionary algorithm. Controllers evolved by EE outperform a hand-designed controller in a simple application. We introduce our approach and its motivations, detail our implementation and initial results, and discuss the advantages and limitations of EE.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Robotics and Autonomous Systems2002\\Watson et al_2002_Embodied Evolution.pdf}
}

@article{borensteinEvolutionImitationMirror2005,
  title = {The Evolution of Imitation and Mirror Neurons in Adaptive Agents},
  author = {Borenstein, Elhanan and Ruppin, Eytan},
  year = {2005},
  month = sep,
  journal = {Cognitive Systems Research},
  series = {Epigenetic {{Robotics}}},
  volume = {6},
  number = {3},
  pages = {229--242},
  issn = {1389-0417},
  doi = {10.1016/j.cogsys.2004.11.004},
  urldate = {2023-01-07},
  abstract = {Imitation is a highly complex cognitive process, involving vision, perception, representation, memory and motor control. The underlying mechanisms that give rise to imitative behavior have attracted a lot of attention in recent years and have been the subject of research in various disciplines, from neuroscience to animal behavior and human psychology. In particular, studies in monkeys and humans have discovered a neural mirror system that demonstrates an internal correlation between the representations of perceptual and motor functionalities. In contradistinction to previous engineering-based approaches, we focus on the evolutionary origins of imitation and present a novel framework for studying the evolution of imitative behavior. We successfully develop evolutionary adaptive agents that demonstrate imitative learning, facilitating a comprehensive study of the emerging underlying neural mechanisms. Interestingly, these agents are found to include a neural ``mirror'' device analogous to those identified in biological systems. Further analysis of these agents' networks reveals complex dynamics, combining innate perceptual-motor coupling with acquired context-action associations, to accomplish the required task. These findings may suggest a universal and fundamental link between the ability to replicate the actions of other (imitation) and the capacity to represent and match others' actions (mirroring).},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Cognitive Systems Research2005\\Borenstein_Ruppin_2005_The evolution of imitation and mirror neurons in adaptive agents.pdf}
}

@article{floreanoEvolutionaryConditionsEmergence2007,
  title = {Evolutionary {{Conditions}} for the {{Emergence}} of {{Communication}} in {{Robots}}},
  author = {Floreano, Dario and Mitri, Sara and Magnenat, St{\'e}phane and Keller, Laurent},
  year = {2007},
  month = mar,
  journal = {Current Biology},
  volume = {17},
  number = {6},
  pages = {514--519},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2007.01.058},
  urldate = {2023-02-24},
  abstract = {Information transfer plays a central role in the biology of most organisms, particularly social species 1, 2. Although the neurophysiological processes by which signals are produced, conducted, perceived, and interpreted are well understood, the conditions conducive to the evolution of communication and the paths by which reliable systems of communication become established remain largely unknown. This is a particularly challenging problem because efficient communication requires tight coevolution between the signal emitted and the response elicited [3]. We conducted repeated trials of experimental evolution with robots that could produce visual signals to provide information on food location. We found that communication readily evolves when colonies consist of genetically similar individuals and when selection acts at the colony level. We identified several distinct communication systems that differed in their efficiency. Once a given system of communication was well established, it constrained the evolution of more efficient communication systems. Under individual selection, the ability to produce visual signals resulted in the evolution of deceptive communication strategies in colonies of unrelated robots and a concomitant decrease in colony performance. This study generates predictions about the evolutionary conditions conducive to the emergence of communication and provides guidelines for designing artificial evolutionary systems displaying spontaneous communication.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Current Biology2007\\Floreano et al_2007_Evolutionary Conditions for the Emergence of Communication in Robots.pdf}
}

@article{dorigoEvolvingSelfOrganizingBehaviors2004,
  title = {Evolving {{Self-Organizing Behaviors}} for a {{Swarm-Bot}}},
  author = {Dorigo, Marco and Trianni, Vito and {\c S}ahin, Erol and Gro{\ss}, Roderich and Labella, Thomas H. and Baldassarre, Gianluca and Nolfi, Stefano and Deneubourg, Jean-Louis and Mondada, Francesco and Floreano, Dario and Gambardella, Luca M.},
  year = {2004},
  month = sep,
  journal = {Autonomous Robots},
  volume = {17},
  number = {2},
  pages = {223--245},
  issn = {1573-7527},
  doi = {10.1023/B:AURO.0000033973.24945.f3},
  urldate = {2023-02-24},
  abstract = {In this paper, we introduce a self-assembling and self-organizing artifact, called a swarm-bot, composed of a swarm of s-bots, mobile robots with the ability to connect to and to disconnect from each other. We discuss the challenges involved in controlling a swarm-bot and address the problem of synthesizing controllers for the swarm-bot using artificial evolution. Specifically, we study aggregation and coordinated motion of the swarm-bot using a physics-based simulation of the system. Experiments, using a simplified simulation model of the s-bots, show that evolution can discover simple but effective controllers for both the aggregation and the coordinated motion of the swarm-bot. Analysis of the evolved controllers shows that they have properties of scalability, that is, they continue to be effective for larger group sizes, and of generality, that is, they produce similar behaviors for configurations different from those they were originally evolved for. The portability of the evolved controllers to real s-bots is tested using a detailed simulation model which has been validated against the real s-bots in a companion paper in this same special issue.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Autonomous Robots2004\\Dorigo et al_2004_Evolving Self-Organizing Behaviors for a Swarm-Bot.pdf}
}

@book{nolfiEvolutionaryRoboticsBiology2004,
  title = {Evolutionary {{Robotics}}: {{The Biology}}, {{Intelligence}}, and {{Technology}} of {{Self-Organizing Machines}}},
  shorttitle = {Evolutionary {{Robotics}}},
  author = {Nolfi, Stefano and Floreano, Dario},
  year = {2004},
  month = jan,
  doi = {10.7551/mitpress/2889.001.0001},
  urldate = {2023-02-23},
  abstract = {Evolutionary robotics is a new technique for the automatic creation of autonomous robots. Inspired by the Darwinian principle of selective reproduction of the f},
  langid = {english}
}

@article{cliffExplorationsEvolutionaryRobotics1993,
  title = {Explorations in {{Evolutionary Robotics}}},
  author = {Cliff, Dave and Husbands, Phil and Harvey, Inman},
  year = {1993},
  month = jun,
  journal = {Adaptive Behavior},
  volume = {2},
  number = {1},
  pages = {73--110},
  issn = {1059-7123, 1741-2633},
  doi = {10.1177/105971239300200104},
  urldate = {2023-02-24},
  abstract = {We discuss the methodological foundations for our work on the development of cognitive architectures, or control systems, for situated autonomous agents. Our focus is the problems of developing sensorimotor control systems for mobile robots, but we also discuss the applicability of our approach to the study of biological systems. We argue that, for agents required to exhibit sophisticated interactions with their environments, complex sensorimotor processing is necessary, and the design, by hand, of control systems capable of such processing is likely to become prohibitively difficult as complexity increases. We propose an automatic design process involving artificial evolution, wherein the basic building blocks used for evolving cognitive architectures are noise-tolerant dynamical neural networks. These networks may be recurrent and should operate in real time. The evolution should be incremental, using an extended and modified version of a genetic algorithm.             Practical constraints suggest that initial architecture evaluations should be done largely in simulation. To support our claims and proposals, we summarize results from some preliminary simulation experiments in which visually guided robots are evolved to operate in simple environments. Significantly, our results demonstrate that robust visually guided control systems evolve from evaluation functions that do not explicitly require monitoring visual input. We outline the difficulties involved in continuing with simulations and conclude by describing specialized visuorobotic equipment, designed to eliminate the need for simulated sensors and actuators.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Adaptive Behavior1993\\Cliff et al_1993_Explorations in Evolutionary Robotics.pdf}
}

@techreport{jeffersonGenesysSystemEvolution1990,
  title = {The {{Genesys System}}: {{Evolution}} as a {{Theme}} in {{Artificial Life}}},
  author = {Jefferson, David and Collins, Robert and Cooper, Claus and Dyer, Michael and Flowers, Margot and Korf, Richard and Taylor, Charles and Wang, Alan},
  year = {1990},
  month = nov,
  urldate = {2023-02-21},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\1990\\Jefferson et al_1990_The Genesys System2.pdf}
}

@article{collinsAntFarmSimulatedEvolution1990,
  title = {{{AntFarm}}: {{Towards Simulated Evolution}}},
  author = {Collins, Robert J},
  year = {1990},
  abstract = {The most easily observed ant behavior is workers foraging for food. Foraging workers do not eat the food, but carry it back to the nest, where it is processed and consumed by all members of the colony. In many species, a high degree of coordination and cooperation between foragers is observed (usually mediated by pheromone communication).},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\_\\Collins_AntFarm.pdf}
}

@article{fontanariEffectLearningEvolution1990,
  title = {The {{Effect}} of {{Learning}} on the {{Evolution}} of {{Asexual Populations}}},
  author = {Fontanari, J F},
  year = {1990},
  abstract = {We study a model for the effect of learning on a population of asexually reproducing individuals . While current models are usually based on simulations of the actual hypothetical organisms, we adopt a classic population genetic approach, which deals directly with gene frequencies. This allows us to investigate the model in great detail, obtaining results which are difficult to obtain using other techniques . In particular, we demonstrate that learning has a drastic effect on evolution, as has already been noted by Hinton and Nowlan [3] using computer simulations. A detailed quantitative description of the temporal behavior of the model is also presented. In particular, an interesting interplay between mutation and learning is demonstrated.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\_\\Fontanari_The Effect of Learning on the Evolution of Asexual Populations.pdf}
}

@article{smithWhenLearningGuides1987,
  title = {When Learning Guides Evolution},
  author = {Smith, John Maynard},
  year = {1987},
  month = oct,
  journal = {Nature},
  volume = {329},
  number = {6142},
  pages = {761--762},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/329761a0},
  urldate = {2022-11-02},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature1987\\Smith_1987_When learning guides evolution.pdf}
}

@article{hintonHowLearningCan1987,
  title = {How {{Learning Can Guide Evolution}}},
  author = {Hinton, Geoffrey E and Nowlan, Steven J},
  year = {1987},
  abstract = {The assumption that acquired characteristics are not inherited is often taken to imply that the adaptations that an organism learns during its lifetime cannot guide the course of evolution. This inference is incorrect (Baldwin, 1896). Learning alters the shape of the search space in which evolution operates and thereby provides good evolutionary paths towards sets of co-adapted alleles. We demonstrate that this effect allows learning organisms to evolve much faster than their nonlearning equivalents, even though the characteristics acquired by the phenotype are not communicated to the genotype.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\undefined\\undefined\\Hinton_Nowlan_How Learning Can Guide Evolution.pdf}
}

@article{hollandGeneticAlgorithms1992,
  title = {Genetic {{Algorithms}}},
  author = {Holland, John H.},
  year = {1992},
  journal = {Scientific American},
  volume = {267},
  number = {1},
  eprint = {24939139},
  eprinttype = {jstor},
  pages = {66--73},
  publisher = {{Scientific American, a division of Nature America, Inc.}},
  issn = {0036-8733},
  urldate = {2023-02-23},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Scientific American1992\\Holland_1992_Genetic Algorithms.pdf}
}

@article{fraserSimulationGeneticSystems1957,
  title = {Simulation of {{Genetic Systems}} by {{Automatic Digital Computers I}}. {{Introduction}}},
  author = {Fraser, A. S.},
  year = {1957},
  journal = {Australian Journal of Biological Sciences},
  volume = {10},
  number = {4},
  pages = {484--491},
  publisher = {{CSIRO PUBLISHING}},
  doi = {10.1071/bi9570484},
  urldate = {2023-02-23},
  abstract = {Methods of setting automatic digital computers to simulate the algebraic aspects of reproduction, segregation, and selection are discussed. The application of these methods to the problem of the importance of linkage in multifactorial inheritance is illustrated by results from the SILLIAC.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Australian Journal of Biological Sciences1957\\Fraser_1957_Simulation of Genetic Systems by Automatic Digital Computers I.pdf}
}

@article{reedSimulationBiologicalEvolution1967,
  title = {Simulation of Biological Evolution and Machine Learning: {{I}}. {{Selection}} of Self-Reproducing Numeric Patterns by Data Processing Machines, Effects of Hereditary Control, Mutation Type and Crossing},
  shorttitle = {Simulation of Biological Evolution and Machine Learning},
  author = {Reed, Jon and Toombs, Robert and Barricelli, Nils Aall},
  year = {1967},
  month = dec,
  journal = {Journal of Theoretical Biology},
  volume = {17},
  number = {3},
  pages = {319--342},
  issn = {0022-5193},
  doi = {10.1016/0022-5193(67)90097-5},
  urldate = {2023-02-23},
  abstract = {The effect of crossing and of different types of mutations (or genetic control) on the speed of selective adaptation has been investigated by data processing machines. The procedure is based on the use of self-reproducing numeric patterns, or arrays of numbers and/or single bits of information. Each number or bit was used to identify a property of the pattern, which could be subject to selection. Some of the properties represented crossing, mutation or reproductive characteristics of the pattern. Some other properties represented other characteristics essential for the pattern's ability to survive and reproduce, for example, by identifying the pattern's strategy in a game of poker used as a means to select the patterns to be reproduced. A measure of the speed of improvement as a function of generation number has been defined and used to compare the improvement under various conditions. The results obtained can be summarized as follows: under conditions simulating regular Mendelian (non-polygenic nor quantitative) inheritance, crossing greatly enhances the speed of selective adaptation, particularly if interaction between the expressions of different hereditary factors is avoided; under conditions simulating polygenic control of quantitative characters, crossing does not enhance the speed of selective adaptation. Furthermore, in a period of rapid selective adaptation the ability to interbreed spreads rapidly in the population as a positively selected characteristic when conditions simulating regular Mendelian inheritance are used. On the other hand, the breeding characteristic spreads less rapidly or not at all under conditions simulating quantitative characters under polygenic control. In the simple game arrangements used in our adaptive selection experiments, the patterns were very often able to develop an optimum game strategy. However, in some instances a ``selective instability'' characterized by statistical fluctuations preventing the achievement of an optimum game strategy was developed. Selective instability, if not properly controlled, is likely to assume larger proportions in experiments of a more complicated nature, and may constitute a serious problem for the practical applications of adaptive selection methods by data processing machines.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Journal of Theoretical Biology1967\\Reed et al_1967_Simulation of biological evolution and machine learning.pdf}
}

@article{smithLogicAnimalConflict1973,
  title = {The {{Logic}} of {{Animal Conflict}}},
  author = {Smith, J. Maynard and Price, G. R.},
  year = {1973},
  month = nov,
  journal = {Nature},
  volume = {246},
  number = {5427},
  pages = {15--18},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/246015a0},
  urldate = {2023-02-24},
  abstract = {Conflicts between animals of the same species usually are of ``limited war'' type, not causing serious injury. This is often explained as due to group or species selection for behaviour benefiting the species rather than individuals. Game theory and computer simulation analyses show, however, that a ``limited war'' strategy benefits individual animals as well as the species.},
  copyright = {1973 Nature Publishing Group},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature1973\\Smith_Price_1973_The Logic of Animal Conflict.pdf}
}

@inproceedings{DBLP:journals/corr/SchulmanMLJA15,
  title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
  booktitle = {4th International Conference on Learning Representations, {{ICLR}} 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael I. and Abbeel, Pieter},
  editor = {Bengio, Yoshua and LeCun, Yann},
  year = {2016},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/SchulmanMLJA15.bib},
  timestamp = {Thu, 25 Jul 2019 14:25:38 +0200}
}

@incollection{williamsSimpleStatisticalGradientFollowing1992,
  title = {Simple {{Statistical Gradient-Following Algorithms}} for {{Connectionist Reinforcement Learning}}},
  booktitle = {Reinforcement {{Learning}}},
  author = {Williams, Ronald J.},
  editor = {Sutton, Richard S.},
  year = {1992},
  series = {The {{Springer International Series}} in {{Engineering}} and {{Computer Science}}},
  pages = {5--32},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4615-3618-5_2},
  urldate = {2023-02-22},
  abstract = {This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.},
  isbn = {978-1-4615-3618-5},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Springer US1992\\Williams_1992_Simple Statistical Gradient-Following Algorithms for Connectionist.pdf}
}

@misc{schulmanProximalPolicyOptimization2017,
  title = {Proximal {{Policy Optimization Algorithms}}},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  year = {2017},
  month = aug,
  number = {arXiv:1707.06347},
  eprint = {arXiv:1707.06347},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1707.06347},
  urldate = {2023-02-22},
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  archiveprefix = {arxiv},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\arXiv2017\\Schulman et al_2017_Proximal Policy Optimization Algorithms.pdf}
}

@article{mnihHumanlevelControlDeep2015,
  title = {Human-Level Control through Deep Reinforcement Learning},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  year = {2015},
  month = feb,
  journal = {Nature},
  volume = {518},
  number = {7540},
  pages = {529--533},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature14236},
  urldate = {2023-02-23},
  abstract = {An artificial agent is developed that learns to play~a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a~performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
  copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature\\2015\\Mnih et al_2015_Human-level control through deep reinforcement learning.pdf}
}

@article{lecunDeepLearning2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature14539},
  urldate = {2023-02-23},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature\\2015\\LeCun et al_2015_Deep learning.pdf}
}

@article{rumelhartLearningRepresentationsBackpropagating1986,
  title = {Learning Representations by Back-Propagating Errors},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  year = {1986},
  month = oct,
  journal = {Nature},
  volume = {323},
  number = {6088},
  pages = {533--536},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/323533a0},
  urldate = {2023-02-23},
  abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal `hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
  copyright = {1986 Nature Publishing Group},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature\\1986\\Rumelhart et al_1986_Learning representations by back-propagating errors.pdf}
}

@article{akamAnteriorCingulateCortex2021,
  title = {The {{Anterior Cingulate Cortex Predicts Future States}} to {{Mediate Model-Based Action Selection}}},
  author = {Akam, Thomas and {Rodrigues-Vaz}, Ines and Marcelo, Ivo and Zhang, Xiangyu and Pereira, Michael and Oliveira, Rodrigo Freire and Dayan, Peter and Costa, Rui M.},
  year = {2021},
  month = jan,
  journal = {Neuron},
  volume = {109},
  number = {1},
  pages = {149-163.e7},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.10.013},
  urldate = {2023-02-26},
  abstract = {Behavioral control is not unitary. It comprises parallel systems, model based and model free, that respectively generate flexible and habitual behaviors. Model-based decisions use predictions of the specific consequences of actions, but how these are implemented in the brain is poorly understood. We used calcium imaging and optogenetics in a sequential decision task for mice to show that the anterior cingulate cortex (ACC) predicts the state that actions will lead to, not simply whether they are good or bad, and monitors whether outcomes match these predictions. ACC represents the complete state space of the task, with reward signals that depend strongly on the state where reward is obtained but minimally on the preceding choice. Accordingly, ACC is necessary only for updating model-based strategies, not for basic reward-driven action reinforcement. These results reveal that ACC is a critical node in model-based control, with a specific role in predicting future states given chosen actions.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Neuron\\2021\\Akam et al_2021_The Anterior Cingulate Cortex Predicts Future States to Mediate Model-Based.pdf}
}

@article{schultzMultipleRewardSignals2000,
  title = {Multiple Reward Signals in the Brain},
  author = {Schultz, Wolfram},
  year = {2000},
  month = dec,
  journal = {Nature Reviews Neuroscience},
  volume = {1},
  number = {3},
  pages = {199--207},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/35044563},
  urldate = {2022-11-17},
  abstract = {This article describes how neurons detect rewards, learn to predict future rewards from past experience, and use reward information for learning, choosing, preparing and executing goal-directed behaviour. It also attempts to place the processing of drug rewards within a general framework of neuronal reward mechanisms.Rewards are defined by their action on behaviour, and are crucial for the survival of the organism. They are vital in the control of homeostasis, sustain learning of new behaviours, the induction of approach behaviour and serve as goals for voluntary, intentional behaviour.Various neurons detect the occurrence of rewards and reward-predicting stimuli, including those of the ascending dopamine systems, and neurons within the striatum, orbitofrontal cortex and amygdala. Some of these neurons seem to provide a reward prediction error signal that could be used for learning mechanisms, whereas others seem to be involved in the perception of individual rewards or objects that signal rewards.Some neurons in the striatum and orbitofrontal cortex do not respond directly to rewards but seem to anticipate the occurrence of future rewards. Some neurons process reward information that is dependent on the relative motivational value of the reward.Neurons in the striatum and different areas of frontal and parietal cortex incorporate information about expected rewards into neuronal activity involved in the production of behaviour leading to reward acquisition. They seem to code the goals of behaviour at the time the behaviour towards the goal is being prepared and executed. Some neurons are active before self-initiated, reward-directed movements and adapt their activity according to ongoing experience.These studies show that different aspects of reward functions are processed by different neurons in different brain structures. The optimal use of reward information for learning and controlling behaviour requires cooperation between these neuronal reward signals.The brain structures involved in the processing of natural rewards also seem to be the critical structures for the action of drugs of abuse. One may ask whether such drugs modify existing neuronal responses to natural rewards or constitute rewards in their own right, and as such engage existing neuronal reward mechanisms, directing subjects towards artificially rewarding goals.This research describes the first steps towards an understanding of how rewards influence behaviour before their receipt and how the brain might use reward information to control learning and goal-directed behaviour.},
  copyright = {2000 Macmillan Magazines Ltd.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature Reviews Neuroscience2000\\Schultz_2000_Multiple reward signals in the brain.pdf}
}

@article{watkinsTechnicalNoteQLearning1992,
  title = {Technical {{Note}}: {{Q-Learning}}},
  shorttitle = {Technical {{Note}}},
  author = {Watkins, Christopher J.C.H. and Dayan, Peter},
  year = {1992},
  month = may,
  journal = {Machine Learning},
  volume = {8},
  number = {3},
  pages = {279--292},
  issn = {1573-0565},
  doi = {10.1023/A:1022676722315},
  urldate = {2023-02-23},
  abstract = {\$\$\textbackslash mathcal\{Q\}\$\$-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Machine Learning\\1992\\Watkins_Dayan_1992_Technical Note.pdf}
}

@article{bartoNeuronlikeAdaptiveElements1983,
  title = {Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problems},
  author = {Barto, Andrew G. and Sutton, Richard S. and Anderson, Charles W.},
  year = {1983},
  month = sep,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {SMC-13},
  number = {5},
  pages = {834--846},
  issn = {2168-2909},
  doi = {10.1109/TSMC.1983.6313077},
  abstract = {It is shown how a system consisting of two neuronlike adaptive elements can solve a difficult learning control problem. The task is to balance a pole that is hinged to a movable cart by applying forces to the cart's base. It is argued that the learning problems faced by adaptive elements that are components of adaptive networks are at least as difficult as this version of the pole-balancing problem. The learning system consists of a single associative search element (ASE) and a single adaptive critic element (ACE). In the course of learning to balance the pole, the ASE constructs associations between input and output by searching under the influence of reinforcement feedback, and the ACE constructs a more informative evaluation function than reinforcement feedback alone can provide. The differences between this approach and other attempts to solve problems using neurolike elements are discussed, as is the relation of this work to classical and instrumental conditioning in animal learning studies and its possible implications for research in the neurosciences.},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\IEEE Transactions on Systems, Man, and Cybernetics1983\\Barto et al_1983_Neuronlike adaptive elements that can solve difficult learning control problems.pdf}
}

@book{suttonReinforcementLearningIntroduction2018,
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {2018},
  series = {Adaptive Computation and Machine Learning Series},
  edition = {Second edition},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
  isbn = {978-0-262-03924-6},
  langid = {english},
  lccn = {Q325.6 .R45 2018},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\The MIT Press2018\\Sutton_Barto_2018_Reinforcement learning.pdf}
}

@article{nicholsTemporallyDynamicReproductive1976,
  title = {Temporally {{Dynamic Reproductive Strategies}} and the {{Concept}} of {{R-}} and {{K-Selection}}},
  author = {Nichols, J. D. and Conley, W. and Batt, B. and Tipton, A. R.},
  year = {1976},
  month = nov,
  journal = {The American Naturalist},
  volume = {110},
  number = {976},
  pages = {995--1005},
  issn = {0003-0147, 1537-5323},
  doi = {10.1086/283122},
  urldate = {2023-02-22},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Zotero\\storage\\QRZYS7G3\\Nichols et al. - 1976 - Temporally Dynamic Reproductive Strategies and the.pdf}
}

@article{piankaKSelection1970,
  title = {On r- and {{K-Selection}}},
  author = {Pianka, Eric R.},
  year = {1970},
  journal = {The American Naturalist},
  volume = {104},
  number = {940},
  eprint = {2459020},
  eprinttype = {jstor},
  pages = {592--597},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\The American Naturalist1970\\Pianka_1970_On r- and K-Selection.pdf}
}

@article{smaersEvolutionMammalianBrain2021,
  title = {The Evolution of Mammalian Brain Size},
  author = {Smaers, J. B. and Rothman, R. S. and Hudson, D. R. and Balanoff, A. M. and Beatty, B. and Dechmann, D. K. N. and {de Vries}, D. and Dunn, J. C. and Fleagle, J. G. and Gilbert, C. C. and Goswami, A. and Iwaniuk, A. N. and Jungers, W. L. and Kerney, M. and Ksepka, D. T. and Manger, P. R. and Mongle, C. S. and Rohlf, F. J. and Smith, N. A. and Soligo, C. and Weisbecker, V. and Safi, K.},
  year = {2021},
  month = apr,
  journal = {Science Advances},
  volume = {7},
  number = {18},
  pages = {eabe2101},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/sciadv.abe2101},
  urldate = {2022-06-16},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Science Advances\\2021\\Smaers et al_2021_The evolution of mammalian brain size.pdf}
}

@article{crispoBaldwinEffectGenetic2007,
  title = {The {{Baldwin Effect}} and {{Genetic Assimilation}}: {{Revisiting Two Mechanisms}} of {{Evolutionary Change Mediated}} by {{Phenotypic Plasticity}}},
  shorttitle = {The {{Baldwin Effect}} and {{Genetic Assimilation}}},
  author = {Crispo, Erika},
  year = {2007},
  journal = {Evolution},
  volume = {61},
  number = {11},
  pages = {2469--2479},
  issn = {1558-5646},
  doi = {10.1111/j.1558-5646.2007.00203.x},
  urldate = {2023-01-25},
  abstract = {Two different, but related, evolutionary theories pertaining to phenotypic plasticity were proposed by James Mark Baldwin and Conrad Hal Waddington. Unfortunately, these theories are often confused with one another. Baldwin's notion of organic selection posits that plasticity influences whether an individual will survive in a new environment, thus dictating the course of future evolution. Heritable variations can then be selected upon to direct phenotypic evolution (i.e., ``orthoplasy''). The combination of these two processes (organic selection and orthoplasy) is now commonly referred to as the ``Baldwin effect.'' Alternately, Waddington's genetic assimilation is a process whereby an environmentally induced phenotype, or ``acquired character,'' becomes canalized through selection acting upon the developmental system. Genetic accommodation is a modern term used to describe the process of heritable changes that occur in response to a novel induction. Genetic accommodation is a key component of the Baldwin effect, and genetic assimilation is a type of genetic accommodation. I here define both the Baldwin effect and genetic assimilation in terms of genetic accommodation, describe cases in which either should occur in nature, and propose that each could play a role in evolutionary diversification.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Evolution2007\\Crispo_2007_The Baldwin Effect and Genetic Assimilation.pdf}
}

@article{houstonPhenotypicPlasticityStatedependent1992,
  title = {Phenotypic Plasticity as a State-Dependent Life-History Decision},
  author = {Houston, Alasdair I. and McNamara, John M.},
  year = {1992},
  month = may,
  journal = {Evolutionary Ecology},
  volume = {6},
  number = {3},
  pages = {243--253},
  issn = {1573-8477},
  doi = {10.1007/BF02214164},
  urldate = {2023-02-22},
  abstract = {A genotype is said to show phenotypic plasticity if it can produce a range of environmentally dependent phenotypes. Plasticity may or may not be adaptive. We consider plasticity as a genetically determined trait and thus find the optimal response of an animal to its environment. Various aspects of this optimal response are illustrated with examples based on reproductive effort. We investigate the selection pressure for plastic as opposed to fixed strategies. An example with spatial heterogeneity is used to compare our approach with that of Stearns and Koella (1986).},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Evolutionary Ecology1992\\Houston_McNamara_1992_Phenotypic plasticity as a state-dependent life-history decision.pdf}
}

@article{simpsonBaldwinEffect1952,
  title = {The {{Baldwin Effect}}},
  author = {Simpson, George Gaylord},
  year = {1952},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\1952\\Simpson_1952_The Baldwin Effect.pdf}
}

@article{baldwin1896new,
  title = {A New Factor in Evolution},
  author = {Baldwin, James Mark},
  year = {1896},
  journal = {The American Naturalist},
  volume = {30},
  number = {354},
  pages = {441--451},
  publisher = {{University of Chicago Press}}
}

@article{kokkoEvolutionMateChoice2003,
  title = {The Evolution of Mate Choice and Mating Biases},
  author = {Kokko, Hanna and Brooks, Robert and Jennions, Michael D. and Morley, Josephine},
  year = {2003},
  month = mar,
  journal = {Proceedings of the Royal Society of London. Series B: Biological Sciences},
  volume = {270},
  number = {1515},
  pages = {653--664},
  publisher = {{Royal Society}},
  doi = {10.1098/rspb.2002.2235},
  urldate = {2022-12-13},
  abstract = {We review the current status of three well\textendash established models (direct benefits, indirect benefits and sensory drive) and one newcomer (antagonistic chase\textendash away) of the evolution of mate choice and the biases that are expressed during choice. We highlight the differences and commonalities in the underlying genetics and evolutionary dynamics of these models. We then argue that progress in understanding the evolution of mate choice is currently hampered by spurious distinctions among models and a misguided tendency to test the processes underlying each model as mutually exclusive alternatives. Finally, we suggest potentially fruitful directions for future theoretical and empirical research.},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Proceedings of the Royal Society of London. Series B Biological Sciences2003\\Kokko et al_2003_The evolution of mate choice and mating biases.pdf}
}

@book{fisher_genetical_2012,
  title = {The Genetical Theory of Natural Selection},
  author = {Fisher, Ronald Aylmer},
  year = {2012},
  publisher = {{Nabu}},
  address = {{U.S.?}},
  isbn = {978-1-176-62502-0},
  langid = {english}
}

@article{damgaardPartialSelfingOptimal1992,
  title = {Partial Selfing as an Optimal Mating Strategy},
  author = {Damgaard, Christian and Couvet, Denis and Loeschcke, Volker},
  year = {1992},
  month = sep,
  journal = {Heredity},
  volume = {69},
  number = {3},
  pages = {289--295},
  issn = {0018-067X, 1365-2540},
  doi = {10.1038/hdy.1992.127},
  urldate = {2023-02-21},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Heredity1992\\Damgaard et al_1992_Partial selfing as an optimal mating strategy.pdf}
}

@article{parkerEvolutionCompetitiveMate1978,
  title = {Evolution of {{Competitive Mate Searching}}},
  author = {Parker, G A},
  year = {1978},
  month = jan,
  journal = {Annual Review of Entomology},
  volume = {23},
  number = {1},
  pages = {173--196},
  issn = {0066-4170, 1545-4487},
  doi = {10.1146/annurev.en.23.010178.001133},
  urldate = {2023-02-21},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Annual Review of Entomology1978\\Parker_1978_Evolution of Competitive Mate Searching.pdf}
}

@article{constantinoLearningOpportunityCost2015,
  title = {Learning the Opportunity Cost of Time in a Patch-Foraging Task},
  author = {Constantino, Sara M. and Daw, Nathaniel D.},
  year = {2015},
  month = dec,
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  volume = {15},
  number = {4},
  pages = {837--853},
  issn = {1531-135X},
  doi = {10.3758/s13415-015-0350-y},
  urldate = {2023-02-21},
  abstract = {Although most decision research concerns choice between simultaneously presented options, in many situations options are encountered serially, and the decision is whether to exploit an option or search for a better one. Such problems have a rich history in animal foraging, but we know little about the psychological processes involved. In particular, it is unknown whether learning in these problems is supported by the well-studied neurocomputational mechanisms involved in more conventional tasks. We investigated how humans learn in a foraging task, which requires deciding whether to harvest a depleting resource or switch to a replenished one. The optimal choice (given by the marginal value theorem; MVT) requires comparing the immediate return from harvesting to the opportunity cost of time, which is given by the long-run average reward. In two experiments, we varied opportunity cost across blocks, and subjects adjusted their behavior to blockwise changes in environmental characteristics. We examined how subjects learned their choice strategies by comparing choice adjustments to a learning rule suggested by the MVT (in which the opportunity cost threshold is estimated as an average over previous rewards) and to the predominant incremental-learning theory in neuroscience, temporal-difference learning (TD). Trial-by-trial decisions were explained better by the MVT threshold-learning rule. These findings expand on the foraging literature, which has focused on steady-state behavior, by elucidating a computational mechanism for learning in switching tasks that is distinct from those used in traditional tasks, and suggest connections to research on average reward rates in other domains of neuroscience.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Cognitive, Affective, & Behavioral Neuroscience2015\\Constantino_Daw_2015_Learning the opportunity cost of time in a patch-foraging task.pdf}
}

@article{calhounForagingBrain2015,
  title = {The Foraging Brain},
  author = {Calhoun, Adam J and Hayden, Benjamin Y},
  year = {2015},
  month = oct,
  journal = {Current Opinion in Behavioral Sciences},
  series = {Neuroeconomics},
  volume = {5},
  pages = {24--31},
  issn = {2352-1546},
  doi = {10.1016/j.cobeha.2015.07.003},
  urldate = {2023-02-06},
  abstract = {Foraging theory is a branch of behavioral ecology that deals with how animals seeking nourishment (foragers) make decisions. Neuroscientists have begun to study foraging decisions because of their ethological relevance and their unique ability to give a glimpse of decision-making as it was evolved to happen. Here we provide a brief introduction to the field, with a focus on two organisms selected to emphasize the breadth of foraging theory: nematodes and monkeys. Despite the obvious differences between these animals, it is clear that several basic principles, especially in the domain of regulation and control of sensory-motor transformations, apply to foraging decisions across taxa. These principles include the importance of the foreground/background structure in foraging decisions and the coordination of multiple input and output modalities to make beneficial long-term choices.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Current Opinion in Behavioral Sciences2015\\Calhoun_Hayden_2015_The foraging brain.pdf}
}

@article{pykeOptimalForagingTheory,
  title = {Optimal {{Foraging Theory}}: {{A Critical Review}}},
  author = {Pyke, G H},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\_\\Pyke_Optimal Foraging Theory.pdf}
}

@article{bomzeLotkaVolterraEquationReplicator1983,
  title = {Lotka-{{Volterra}} Equation and Replicator Dynamics: {{A}} Two-Dimensional Classification},
  shorttitle = {Lotka-{{Volterra}} Equation and Replicator Dynamics},
  author = {Bomze, Immanuel M.},
  year = {1983},
  month = oct,
  journal = {Biological Cybernetics},
  volume = {48},
  number = {3},
  pages = {201--211},
  issn = {1432-0770},
  doi = {10.1007/BF00318088},
  urldate = {2023-02-22},
  abstract = {The replicator equation arises if one equips a certain game theoretical model for the evolution of behaviour in animal conflicts with dynamics. It serves to model many biological processes not only in sociobiology but also in population genetics, mathematical ecology and even in prebiotic evolution. After a short survey of these applications, a complete classification of the two-dimensional phase flows is presented. The methods are also used to obtain a classification of phase portraits of the well-known generalized Lotka-Volterra equation in the plane.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Biological Cybernetics\\1983\\Bomze_1983_Lotka-Volterra equation and replicator dynamics.pdf}
}

@book{hastingsPopulationBiologyConcepts1997,
  title = {Population {{Biology}}: {{Concepts}} and {{Models}}},
  author = {Hastings, Alan},
  year = {1997},
  publisher = {{Springer}},
  urldate = {2023-02-21},
  langid = {english}
}

@book{levinsEvolutionChangingEnvironments1968,
  title = {Evolution in {{Changing Environments}}: {{Some Theoretical Explorations}}. ({{MPB-2}})},
  shorttitle = {Evolution in {{Changing Environments}}},
  author = {Levins, Richard},
  year = {1968},
  eprint = {j.ctvx5wbbh},
  eprinttype = {jstor},
  publisher = {{Princeton University Press}},
  doi = {10.2307/j.ctvx5wbbh},
  urldate = {2023-02-22},
  abstract = {Professor Levins, one of the leading explorers in the field of integrated population biology, considers the mutual interpenetration and joint evolution of organism and environment, occurring on several levels at once. Physiological and behavioral adaptations to short-term fluctuations of the environment condition the responses of populations to long-term changes and geographic gradients. These in turn affect the way species divide the environments among themselves in communities, and, therefore, the numbers of species which can coexist. Environment is treated here abstractly as pattern: patchiness, variability, range, etc. Populations are studied in their patterns: local heterogeneity, geographic variability, faunistic diversity, etc.},
  isbn = {978-0-691-07959-2}
}

@article{frankFisherFundamentalTheorem1992,
  title = {Fisher's Fundamental Theorem of Natural Selection},
  author = {Frank, Steven A. and Slatkin, Montgomery},
  year = {1992},
  month = mar,
  journal = {Trends in Ecology \& Evolution},
  volume = {7},
  number = {3},
  pages = {92--95},
  issn = {0169-5347},
  doi = {10.1016/0169-5347(92)90248-A},
  urldate = {2023-02-22},
  abstract = {Fisher's Fundamental Theorem of natural selection is one of the most widely cited theories in evolutionary biology. Yet it has been argued that the standard interpretation of the theorem is very different from what Fisher meant to say. What Fisher really meant can be illustrated by looking in a new way at a recent model for the evolution of clutch size. Why Fisher was misunderstood depends, in part, on the contrasting views of evolution promoted by Fisher and Wright.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Trends in Ecology & Evolution\\1992\\Frank_Slatkin_1992_Fisher's fundamental theorem of natural selection.pdf}
}

@article{codyOptimizationEcology1974,
  title = {Optimization in {{Ecology}}},
  author = {Cody, Martin L.},
  year = {1974},
  journal = {Science},
  volume = {183},
  number = {4130},
  eprint = {1737847},
  eprinttype = {jstor},
  pages = {1156--1164},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  urldate = {2023-02-22},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Science\\1974\\Cody_1974_Optimization in Ecology.pdf}
}

@inproceedings{stearnsNaturalSelectionFitness1986,
  title = {Natural {{Selection}} and {{Fitness}}, {{Adaptation}} and {{Constraint}}},
  booktitle = {Patterns and {{Processes}} in the {{History}} of {{Life}}},
  author = {Stearns, S. C.},
  editor = {Raup, D. M. and Jablonski, D.},
  year = {1986},
  series = {Dahlem {{Workshop Reports}}},
  pages = {23--44},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-70831-2_3},
  abstract = {Biologists often use abstractions developed in one context to describe material mechanisms observed in another, where the connection is not as certain. This article discusses four abstractions: ``natural selection,'' ``fitness,'' ``adaptation,'' and ``constraint.'' Natural selection operates simultaneously on all levels of the biological hierarchy, but its strength, determined by cycle time and proportion of variation accounted for, varies by orders of magnitude across levels. For traits varying at all levels, selection within populations must dominate. For traits fixed within but varying among clades, only selection at higher levels can have any impact. Here selection will be slow but can produce major change. Fitness is not a trait but a technical embodiment of assumptions about selection. Fitness definitions are either short-term of long-term and measure either abundance or risk minimization, and are either absolute (intrinsic) or relative (extrinsic). Within specialties one can often use different fitness definitions to reach the same prediction. Because fitness definitions are simply mental tools, we are free to change definitions if by so doing we gain predictive and explanatory power. No universal definition of fitness can yet be made, nor is one ever likely to be made, because different problems define different fitness definitions. Adaptations are polished products of natural selection with particularly clear relationships to particular problems faced by the organisms that posses them. They have not often been produced by selection among clades, which has produced the appearance of ``history'' \textemdash{} rough, clade-specific patterns \textemdash{} because selective events have been few. Constraint usually means ``an explanation imported from outside the local context to explain the limits on the patterns observed.'' Constraints generated by a particular set of processes, here called ``intermediate structure,'' are clade-specific and intervene between genes and phenotype to produce comparative biology. These structures are currently either formal (e.g., genetic covariance matrices) or material (e.g., hormonal integration). If we could make the formal aspects of intermediate structure material, precise, concrete, and subject to observation and experiment, we could explain much of the stasis and clade-specificity seen in the fossil record.},
  isbn = {978-3-642-70831-2},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Springer1986\\Stearns_1986_Natural Selection and Fitness, Adaptation and Constraint.pdf}
}

@book{williams_natural_1992,
  title = {Natural Selection: Domains, Levels, and Challenges},
  shorttitle = {Natural Selection},
  author = {Williams, George C.},
  year = {1992},
  series = {Oxford Series in Ecology and Evolution},
  publisher = {{Oxford University Press}},
  address = {{New York}},
  isbn = {978-0-19-506933-4},
  keywords = {Natural selection}
}

@book{darwin1859,
  title = {On the Origin of Species by Means of Natural Selection},
  author = {Darwin, Charles},
  year = {1859},
  publisher = {{Murray}},
  address = {{London}},
  added-at = {2008-05-27T04:02:47.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/2d70d713c717fb28384fb073c9f6dfbc2/neilernst},
  citeulike-article-id = {2376343},
  interhash = {c738acbb887362be5b0e6abc51be42d3},
  intrahash = {d70d713c717fb28384fb073c9f6dfbc2},
  priority = {2},
  keywords = {evolution},
  timestamp = {2008-05-27T04:02:47.000+0200}
}

@article{perryNeuralMechanismsReward2013,
  title = {Neural {{Mechanisms}} of {{Reward}} in {{Insects}}},
  author = {Perry, Clint J. and Barron, Andrew B.},
  year = {2013},
  journal = {Annual Review of Entomology},
  volume = {58},
  number = {1},
  pages = {543--562},
  doi = {10.1146/annurev-ento-120811-153631},
  urldate = {2023-03-07},
  abstract = {Reward seeking is a major motivator and organizer of behavior, and animals readily learn to modify their behavior to more easily obtain reward, or to respond to stimuli that are predictive of reward. Here, we compare what is known of reward processing mechanisms in insects with the well-studied vertebrate reward systems. In insects almost all of what is known of reward processing is derived from studies of reward learning. This is localized to the mushroom bodies and antennal lobes and organized by a network of hierarchically arranged modulatory circuits, especially those involving octopamine and dopamine. Neurogenetic studies with Drosophila have identified distinct circuit elements for reward learning, ``wanting,'' and possibly ``liking'' in Drosophila, suggesting a modular structure to the insect reward processing system, which broadly parallels that of the mammals in terms of functional organization.},
  pmid = {23020615},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Annual Review of Entomology\\2013\\Perry_Barron_2013_Neural Mechanisms of Reward in Insects.pdf}
}

@article{strausfeldDeepHomologyArthropod2013,
  title = {Deep {{Homology}} of {{Arthropod Central Complex}} and {{Vertebrate Basal Ganglia}}},
  author = {Strausfeld, Nicholas J. and Hirth, Frank},
  year = {2013},
  month = apr,
  journal = {Science},
  volume = {340},
  number = {6129},
  pages = {157--161},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.1231828},
  urldate = {2023-02-20},
  abstract = {The arthropod central complex and vertebrate basal ganglia derive from embryonic basal forebrain lineages that are specified by an evolutionarily conserved genetic program leading to interconnected neuropils and nuclei that populate the midline of the forebrain-midbrain boundary region. In the substructures of both the central complex and basal ganglia, network connectivity and neuronal activity mediate control mechanisms in which inhibitory (GABAergic) and modulatory (dopaminergic) circuits facilitate the regulation and release of adaptive behaviors. Both basal ganglia and central complex dysfunction result in behavioral defects including motor abnormalities, impaired memory formation, attention deficits, affective disorders, and sleep disturbances. The observed multitude of similarities suggests deep homology of arthropod central complex and vertebrate basal ganglia circuitries underlying the selection and maintenance of behavioral actions.}
}

@article{tessmar-raibleConservedSensoryNeurosecretoryCell2007,
  title = {Conserved {{Sensory-Neurosecretory Cell Types}} in {{Annelid}} and {{Fish Forebrain}}: {{Insights}} into {{Hypothalamus Evolution}}},
  shorttitle = {Conserved {{Sensory-Neurosecretory Cell Types}} in {{Annelid}} and {{Fish Forebrain}}},
  author = {{Tessmar-Raible}, Kristin and Raible, Florian and Christodoulou, Foteini and Guy, Keren and Rembold, Martina and Hausen, Harald and Arendt, Detlev},
  year = {2007},
  month = jun,
  journal = {Cell},
  volume = {129},
  number = {7},
  pages = {1389--1400},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2007.04.041},
  urldate = {2023-03-10},
  abstract = {Neurosecretory control centers form part of the~forebrain in many animal phyla, including vertebrates, insects, and annelids. The evolutionary origin of these centers is largely unknown. To~identify conserved, and thus phylogenetically ancient, components of neurosecretory brain centers, we characterize and compare neurons that express the prohormone vasotocin (vasopressin/oxytocin)-neurophysin in the developing forebrain of the annelid Platynereis dumerilii and of the zebrafish. These neurons express the same tissue-restricted microRNA, miR-7, and conserved, cell-type-specific combinations of transcription factors (nk2.1, rx, and otp) that specify their identity, as evidenced by the specific requirement of zebrafish rx3 for vasotocin-neurophysin expression. MiR-7 also labels another shared population of neurons containing RFamides. Since the vasotocinergic and RFamidergic neurons appear to be directly sensory in annelid and fish, we propose that cell types with dual sensory-neurosecretory properties were the starting point for the evolution of neurosecretory brain centers in Bilateria.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Cell2007\\Tessmar-Raible et al_2007_Conserved Sensory-Neurosecretory Cell Types in Annelid and Fish Forebrain.pdf}
}

@article{oconnellVertebrateMesolimbicReward2011,
  title = {The {{Vertebrate}} Mesolimbic Reward System and Social Behavior Network: {{A}} Comparative Synthesis},
  shorttitle = {The {{Vertebrate}} Mesolimbic Reward System and Social Behavior Network},
  author = {O'Connell, Lauren A. and Hofmann, Hans A.},
  year = {2011},
  journal = {Journal of Comparative Neurology},
  volume = {519},
  number = {18},
  pages = {3599--3639},
  issn = {1096-9861},
  doi = {10.1002/cne.22735},
  urldate = {2023-01-06},
  abstract = {All animals evaluate the salience of external stimuli and integrate them with internal physiological information into adaptive behavior. Natural and sexual selection impinge on these processes, yet our understanding of behavioral decision-making mechanisms and their evolution is still very limited. Insights from mammals indicate that two neural circuits are of crucial importance in this context: the social behavior network and the mesolimbic reward system. Here we review evidence from neurochemical, tract-tracing, developmental, and functional lesion/stimulation studies that delineates homology relationships for most of the nodes of these two circuits across the five major vertebrate lineages: mammals, birds, reptiles, amphibians, and teleost fish. We provide for the first time a comprehensive comparative analysis of the two neural circuits and conclude that they were already present in early vertebrates. We also propose that these circuits form a larger social decision-making (SDM) network that regulates adaptive behavior. Our synthesis thus provides an important foundation for understanding the evolution of the neural mechanisms underlying reward processing and behavioral regulation. J. Comp. Neurol. 519:3599\textendash 3639, 2011. \textcopyright{} 2011 Wiley-Liss, Inc.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Journal of Comparative Neurology2011\\O'Connell_Hofmann_2011_The Vertebrate mesolimbic reward system and social behavior network.pdf}
}

@book{kaasEvolutionaryNeuroscience2020,
  title = {Evolutionary {{Neuroscience}}},
  editor = {Kaas, Jon H},
  year = {2020},
  month = jan,
  publisher = {{Academic Press}},
  address = {{London}},
  doi = {10.1016/B978-0-12-820584-6.01001-1},
  urldate = {2023-02-20},
  abstract = {Evolutionary Neuroscience, Second Edition, is a collection of chapters on brain evolution that combines selected topics from the recent comprehensive reference, Evolution of Nervous Systems (Elsevier, Academic Press, 2017, 9780128040423). The selected chapters cover a broad range of topics, from historical theory, to the most recent deductions from comparative studies of brains. The articles are organized in sections focused on history, concepts and theory, the evolution of brains from early vertebrates to present-day fishes, amphibians, reptiles and birds, the evolution of mammalian brains, and the evolution of primate brains, including human brains. Each chapter is written by a leader or leaders in the field. Specific topics include brain character reconstruction, principles of brain scaling, basic features of vertebrate brains, the evolution of the major sensory systems, other parts of brains, what we can learn from fossils, the origin of neocortex, and the evolution of specializations of human brains. The collection of articles will be interesting to anyone who is curious about how brains evolved from the simpler nervous systems of the first vertebrates into the many different complex forms now found in present-day vertebrates.},
  isbn = {978-0-12-820584-6},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Academic Press2020\\2020_Front Matter.pdf}
}

@article{grillnerEvolutionaryOriginVertebrate2013,
  title = {The Evolutionary Origin of the Vertebrate Basal Ganglia and Its Role in Action Selection},
  author = {Grillner, Sten and Robertson, Brita and {Stephenson-Jones}, Marcus},
  year = {2013},
  journal = {The Journal of Physiology},
  volume = {591},
  number = {22},
  pages = {5425--5431},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.2012.246660},
  urldate = {2023-02-17},
  abstract = {The group of nuclei within the basal ganglia of the forebrain is central to the control of movement. We present data showing that the structure and function of the basal ganglia have been conserved throughout vertebrate evolution over some 560 million years. The interaction between the different nuclei within the basal ganglia is conserved as well as the cellular and synaptic properties and transmitters. We consider the role of the conserved basal ganglia circuitry for basic patterns of motor behaviour controlled via brainstem circuits. The output of the basal ganglia consists of tonically active GABAergic neurones, which target brainstem motor centres responsible for different patterns of behaviour, such as eye and locomotor movements, posture, and feeding. A prerequisite for activating or releasing a motor programme is that this GABAergic inhibition is temporarily reduced. This can be achieved through activation of GABAergic projection neurons from striatum, the input level of the basal ganglia, given an appropriate synaptic drive from cortex, thalamus and the dopamine system. The tonic inhibition of the motor centres at rest most likely serves to prevent the different motor programmes from becoming active when not intended. Striatal projection neurones are subdivided into one group with dopamine 1 receptors that provides increased excitability of the direct pathway that can initiate movements, while inhibitory dopamine 2 receptors are expressed on neurones that instead inhibit movements and are part of the `indirect loop' in mammals as well as lamprey. We review the evidence showing that all basic features of the basal ganglia have been conserved throughout vertebrate phylogeny, and discuss these findings in relation to the role of the basal ganglia in selection of behaviour.},
  copyright = {\textcopyright{} 2013 The Authors. The Journal of Physiology \textcopyright{} 2013 The Physiological Society},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\The Journal of Physiology2013\\Grillner et al_2013_The evolutionary origin of the vertebrate basal ganglia and its role in action.pdf}
}

@article{leknesCommonNeurobiologyPain2008,
  title = {A Common Neurobiology for Pain and Pleasure},
  author = {Leknes, Siri and Tracey, Irene},
  year = {2008},
  month = apr,
  journal = {Nature Reviews Neuroscience},
  volume = {9},
  number = {4},
  pages = {314--320},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn2333},
  urldate = {2023-03-13},
  abstract = {Tracey and Leknes review the emerging evidence of extensive similarities between the anatomical substrates and signalling systems that mediate painful and pleasant sensations. Understanding the relationship between these powerful modulators of behaviour could be important for alleviating unnecessary suffering and improving well-being.},
  copyright = {2008 Nature Publishing Group},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature Reviews Neuroscience2008\\Leknes_Tracey_2008_A common neurobiology for pain and pleasure.pdf}
}

@article{matsumotoLateralHabenulaSource2007,
  title = {Lateral Habenula as a Source of Negative Reward Signals in Dopamine Neurons},
  author = {Matsumoto, Masayuki and Hikosaka, Okihide},
  year = {2007},
  month = jun,
  journal = {Nature},
  volume = {447},
  number = {7148},
  pages = {1111--1115},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature05860},
  urldate = {2023-03-13},
  abstract = {The involvement of dopaminergic neurons in motor symptoms is evident from their role in Parkinson's disease. Yet the neurons that release dopamine carry signals related to rewards, not body movements. As a solution to this puzzle, recent theories suggest that the reward-related dopamine signals are used for learning of motor behaviours. Until now it has been unclear how dopamine neurons acquire the reward-related signals. Now in an experiment in rhesus monkeys performing a visually guided task for reward, Masayuki Matsumoto and Okihide Hikosaka show that a small brain area called the lateral habenula controls dopamine neurons by inhibiting them and thereby suppressing less rewarding eye movements. This discovery opens up possibilities for new research on the links between emotion, motivation and motor behaviours.},
  copyright = {2007 Nature Publishing Group},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature2007\\Matsumoto_Hikosaka_2007_Lateral habenula as a source of negative reward signals in dopamine neurons.pdf}
}

@article{mondoloniRewardAversionEncoding2022,
  title = {Reward and Aversion Encoding in the Lateral Habenula for Innate and Learned Behaviours},
  author = {Mondoloni, Sarah and Mameli, Manuel and Congiu, Mauro},
  year = {2022},
  month = jan,
  journal = {Translational Psychiatry},
  volume = {12},
  number = {1},
  pages = {1--8},
  publisher = {{Nature Publishing Group}},
  issn = {2158-3188},
  doi = {10.1038/s41398-021-01774-0},
  urldate = {2023-03-18},
  abstract = {Throughout life, individuals experience a vast array of positive and aversive events that trigger adaptive behavioural responses. These events are often unpredicted and engage actions that are likely anchored on innate behavioural programs expressed by each individual member of virtually all animal species. In a second step, environmental cues, that are initially neutral, acquire value through the association with external sensory stimuli, and become instrumental to predict upcoming positive or negative events. This process ultimately prompts learned goal-directed actions allowing the pursuit of rewarding experience or the avoidance of a danger. Both innate and learned behavioural programs are evolutionarily conserved and fundamental for survival. Among the brain structures participating in the encoding of positive/negative stimuli and contributing to innate and learned behaviours is the epithalamic lateral habenula (LHb). The LHb provides top-down control of monoaminergic systems, responds to unexpected appetitive/aversive stimuli as well as external cues that predict the upcoming rewards or punishments. Accordingly, the LHb controls a number of behaviours that are innate (originating from unpredicted stimuli), and learned (stemming from predictive cues). In this review, we will discuss the progresses that rodent's experimental work made in identifying how LHb activity governs these vital processes, and we will provide a view on how these findings integrate within a complex circuit connectivity.},
  copyright = {2021 The Author(s)},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Translational Psychiatry2022\\Mondoloni et al_2022_Reward and aversion encoding in the lateral habenula for innate and learned.pdf}
}

@article{moralesLikingWantingEating2020,
  title = {`{{Liking}}' and `Wanting' in Eating and Food Reward: {{Brain}} Mechanisms and Clinical Implications},
  shorttitle = {`{{Liking}}' and `Wanting' in Eating and Food Reward},
  author = {Morales, Ileana and Berridge, Kent C.},
  year = {2020},
  month = dec,
  journal = {Physiology \& Behavior},
  volume = {227},
  pages = {113152},
  issn = {0031-9384},
  doi = {10.1016/j.physbeh.2020.113152},
  urldate = {2023-03-14},
  abstract = {It is becoming clearer how neurobiological mechanisms generate `liking' and `wanting' components of food reward. Mesocorticolimbic mechanisms that enhance `liking' include brain hedonic hotspots, which are specialized subregions that are uniquely able to causally amplify the hedonic impact of palatable tastes. Hedonic hotspots are found in nucleus accumbens medial shell, ventral pallidum, orbitofrontal cortex, insula cortex, and brainstem. In turn, a much larger mesocorticolimbic circuitry generates `wanting' or incentive motivation to obtain and consume food rewards. Hedonic and motivational circuitry interact together and with hypothalamic homeostatic circuitry, allowing relevant physiological hunger and satiety states to modulate `liking' and `wanting' for food rewards. In some conditions such as drug addiction, `wanting' is known to dramatically detach from `liking' for the same reward, and this may also occur in over-eating disorders. Via incentive sensitization, `wanting' selectively becomes higher, especially when triggered by reward cues when encountered in vulnerable states of stress, etc. Emerging evidence suggests that some cases of obesity and binge eating disorders may reflect an incentive-sensitization brain signature of cue hyper-reactivity, causing excessive `wanting' to eat. Future findings on the neurobiological bases of `liking' and `wanting' can continue to improve understanding of both normal food reward and causes of clinical eating disorders.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Physiology & Behavior\\2020\\Morales_Berridge_2020_‘Liking’ and ‘wanting’ in eating and food reward.pdf}
}

@article{mobbsSpaceTimeFear2020,
  title = {Space, {{Time}}, and {{Fear}}: {{Survival Computations}} along {{Defensive Circuits}}},
  shorttitle = {Space, {{Time}}, and {{Fear}}},
  author = {Mobbs, Dean and Headley, Drew B. and Ding, Weilun and Dayan, Peter},
  year = {2020},
  month = mar,
  journal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {3},
  pages = {228--241},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2019.12.016},
  urldate = {2023-03-18},
  abstract = {Naturalistic observations show that decisions to avoid or escape predators occur at different spatiotemporal scales and that they are supported by different computations and neural circuits. At their extremes, proximal threats are addressed by a limited repertoire of reflexive and myopic actions, reflecting reduced decision and state spaces and model-free (MF) architectures. Conversely, distal threats allow increased information processing supported by model-based (MB) operations, including affective prospection, replay, and planning. However, MF and MB computations are often intertwined, and under conditions of safety the foundations for future effective reactive execution can be laid through MB instruction of MF control. Together, these computations are associated with distinct population codes embedded within a distributed defensive circuitry whose goal is to determine and realize the best policy.},
  langid = {english}
}

@article{baxterAmygdalaReward2002,
  title = {The Amygdala and Reward},
  author = {Baxter, Mark G. and Murray, Elisabeth A.},
  year = {2002},
  month = jul,
  journal = {Nature Reviews Neuroscience},
  volume = {3},
  number = {7},
  pages = {563--573},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn875},
  urldate = {2023-03-18},
  abstract = {It is widely accepted that the amygdala is associated with fear conditioning and the processing of negative emotions. But this structure is also involved in the processing of positive emotions, and particularly in learning about the positive value of stimuli. A number of types of behaviour that involve reward processing are independent of the amygdala. These include visual-discrimination learning, visuomotor conditional learning, food-cup approach (Pavlovian conditioning), and food and object preferences. These behaviours, in the absence of stimulus\textendash reward association mediated by the amygdala, could rely on stimulus\textendash response learning or cortical representations of the value of stimuli. Different divisions of the amygdala mediate different kinds of stimulus\textendash value association. Lesions of the basolateral nucleus of the amygdala impair performance on tasks that require linking an object with a current (as opposed to a consistent) stimulus value. Examples of paradigms that can expose this effect include reinforcer devaluation (in which the value of a reinforcer changes) and second-order conditioning (in which a previously neutral stimulus comes to acquire the value of the reinforcer with which it has been paired). Neurons of the basolateral amygdala, like neurons in the prefrontal cortex, show complex patterns of firing that include specific responses to particular objects, such as foods. These patterns of firing can be modulated by reinforcer devaluation. Lesions of the central nucleus of the amygdala, by contrast, impair Pavlovian approach or avoidance responses to specific conditioned stimuli. An example of Pavlovian approach is the increased rearing response of rats to a light that is repeatedly paired with food delivery. Patients with bilateral amygdala damage perform poorly on laboratory-based gambling tasks. Unlike patients with damage to the prefrontal cortex, who are also impaired on these tasks, patients with amygdala damage fail to generate normal changes in skin-conductance response and other autonomic responses when they 'win' or 'lose' money. Their inability to learn a winning strategy might result from an inability to generate the appropriate affective state. Future work should aim to integrate these functions of the amygdala with its other functions, such as the production of fear responses and attentional processing.},
  copyright = {2002 Nature Publishing Group},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature Reviews Neuroscience2002\\Baxter_Murray_2002_The amygdala and reward.pdf}
}

@article{moscarelloCentralNucleusAmygdala2022,
  title = {The Central Nucleus of the Amygdala and the Construction of Defensive Modes across the Threat-Imminence Continuum},
  author = {Moscarello, Justin M. and Penzo, Mario A.},
  year = {2022},
  month = aug,
  journal = {Nature Neuroscience},
  volume = {25},
  number = {8},
  pages = {999--1008},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-022-01130-5},
  urldate = {2023-03-15},
  abstract = {In nature, animals display defensive behaviors that reflect the spatiotemporal distance of threats. Laboratory-based paradigms that elicit specific defensive responses in rodents have provided valuable insight into the brain mechanisms that mediate the construction of defensive modes with varying degrees of threat imminence. In this Review, we discuss accumulating evidence that the central nucleus of the amygdala (CeA) plays a key role in this process. Specifically, we propose that the mutually inhibitory circuits of the CeA use a winner-takes-all strategy that supports transitioning across defensive modes and the execution of specific defensive behaviors to previously formed threat associations. Our proposal provides a conceptual framework in which seemingly divergent observations regarding CeA function can be interpreted and identifies various areas of priority for future research.},
  copyright = {2022 This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature Neuroscience2022\\Moscarello_Penzo_2022_The central nucleus of the amygdala and the construction of defensive modes.pdf}
}

@article{royRepresentationAversivePrediction2014,
  title = {Representation of Aversive Prediction Errors in the Human Periaqueductal Gray},
  author = {Roy, Mathieu and Shohamy, Daphna and Daw, Nathaniel and Jepma, Marieke and Wimmer, G. Elliott and Wager, Tor D.},
  year = {2014},
  month = nov,
  journal = {Nature Neuroscience},
  volume = {17},
  number = {11},
  pages = {1607--1612},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.3832},
  urldate = {2023-03-17},
  abstract = {This study uses fMRI in humans to find that prediction errors about pain are encoded in the periaqueductal gray. Modeling inter-area connectivity suggests that the ventromedial prefrontal cortex and the putamen pass on a value-related signal to this midbrain structure, which then conveys predictor error signals to prefrontal regions that regulate behavior.},
  copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature Neuroscience2014\\Roy et al_2014_Representation of aversive prediction errors in the human periaqueductal gray.pdf}
}

@article{oliveiraRolePAGAntinociception2001,
  title = {Role of {{PAG}} in the Antinociception Evoked from the Medial or Central Amygdala in Rats},
  author = {Oliveira, Marina A and Prado, Wiliam A},
  year = {2001},
  month = jan,
  journal = {Brain Research Bulletin},
  volume = {54},
  number = {1},
  pages = {55--63},
  issn = {0361-9230},
  doi = {10.1016/S0361-9230(00)00420-2},
  urldate = {2023-03-18},
  abstract = {The effects of stimulating the periaqueductal gray (PAG) against the rat tail flick reflex (TFR) was not changed significantly by the microinjection of lidocaine (5\%/0.5 {$\mu$}l) into the medial (ME) or central (CE) nuclei of the amygdala. In contrast, lidocaine into the PAG blocked the effects from the ME or CE. The microinjection of naloxone (1 {$\mu$}g), {$\beta$}-funaltrexamine (2 {$\mu$}g), propranolol (1{$\mu$}g), or methysergide (1{$\mu$}g), but not atropine (1 {$\mu$}g) or mecamylamine (1 {$\mu$}g) into the PAG significantly reduced the effects from the CE. The effect from the ME was not altered significantly by microinjecting naloxone into the PAG. Therefore, the ME or CE are unlikely to be intermediary stations for depression of the TFR evoked by stimulating the PAG, but the PAG may be a relay station for the effects of stimulating the ME or CE. The circuitry activated from the CE, but not the ME, utilises opioid mediation in the PAG. The effect from the CE depends at least on {$\mu$}-opioid, serotonergic, and probably {$\beta$}-adrenergic mediation in the PAG.},
  langid = {english}
}

@article{botvinickConflictMonitoringSelectionforaction1999,
  title = {Conflict Monitoring versus Selection-for-Action in Anterior Cingulate Cortex},
  author = {Botvinick, Matthew and Nystrom, Leigh E. and Fissell, Kate and Carter, Cameron S. and Cohen, Jonathan D.},
  year = {1999},
  month = nov,
  journal = {Nature},
  volume = {402},
  number = {6758},
  pages = {179--181},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/46035},
  urldate = {2023-02-17},
  abstract = {The anterior cingulate cortex (ACC), on the medial surface of the frontal lobes of the brain, is widely believed to be involved in the regulation of attention1,2. Beyond this, however, its specific contribution to cognition remains uncertain. One influential theory has interpreted activation within the ACC as reflecting `selection-for-action'3,4,5, a set of processes that guide the selection of environmental objects as triggers of or targets for action. We have proposed an alternative hypothesis, in which the ACC serves not to exert top-down attentional control but instead to detect and signal the occurrence of conflicts in information processing6,7,8. Here, to test this theory against the selection-for-action theory, we used functional magnetic resonance imaging to measure brain activation during performance of a task where, for a particular subset of trials, the strength of selection-for-action is inversely related to the degree of response conflict. Activity within the ACC was greater during trials featuring high levels of conflict (and weak selection-for-action) than during trials with low levels of conflict (and strong selection-for-action), providing evidence in favour of the conflict-monitoring account of ACC function.},
  copyright = {1999 Macmillan Magazines Ltd.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature\\1999\\Botvinick et al_1999_Conflict monitoring versus selection-for-action in anterior cingulate cortex.pdf}
}

@article{ferencziPrefrontalCorticalRegulation2016,
  title = {Prefrontal Cortical Regulation of Brainwide Circuit Dynamics and Reward-Related Behavior},
  author = {Ferenczi, Emily A. and Zalocusky, Kelly A. and Liston, Conor and Grosenick, Logan and Warden, Melissa R. and Amatya, Debha and Katovich, Kiefer and Mehta, Hershel and Patenaude, Brian and Ramakrishnan, Charu and Kalanithi, Paul and Etkin, Amit and Knutson, Brian and Glover, Gary H. and Deisseroth, Karl},
  year = {2016},
  month = jan,
  journal = {Science},
  volume = {351},
  number = {6268},
  pages = {aac9698},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aac9698},
  urldate = {2023-02-17},
  abstract = {Motivation for reward drives adaptive behaviors, whereas impairment of reward perception and experience (anhedonia) can contribute to psychiatric diseases, including depression and schizophrenia. We sought to test the hypothesis that the medial prefrontal cortex (mPFC) controls interactions among specific subcortical regions that govern hedonic responses. By using optogenetic functional magnetic resonance imaging to locally manipulate but globally visualize neural activity in rats, we found that dopamine neuron stimulation drives striatal activity, whereas locally increased mPFC excitability reduces this striatal response and inhibits the behavioral drive for dopaminergic stimulation. This chronic mPFC overactivity also stably suppresses natural reward-motivated behaviors and induces specific new brainwide functional interactions, which predict the degree of anhedonia in individuals. These findings describe a mechanism by which mPFC modulates expression of reward-seeking behavior, by regulating the dynamical interactions between specific distant subcortical regions.},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Science\\2016\\Ferenczi et al_2016_Prefrontal cortical regulation of brainwide circuit dynamics and reward-related.pdf}
}

@article{haberRewardCircuitLinking2010,
  title = {The {{Reward Circuit}}: {{Linking Primate Anatomy}} and {{Human Imaging}}},
  shorttitle = {The {{Reward Circuit}}},
  author = {Haber, Suzanne N. and Knutson, Brian},
  year = {2010},
  month = jan,
  journal = {Neuropsychopharmacology},
  volume = {35},
  number = {1},
  pages = {4--26},
  publisher = {{Nature Publishing Group}},
  issn = {1740-634X},
  doi = {10.1038/npp.2009.129},
  urldate = {2022-12-08},
  abstract = {Although cells in many brain regions respond to reward, the cortical-basal ganglia circuit is at the heart of the reward system. The key structures in this network are the anterior cingulate cortex, the orbital prefrontal cortex, the ventral striatum, the ventral pallidum, and the midbrain dopamine neurons. In addition, other structures, including the dorsal prefrontal cortex, amygdala, hippocampus, thalamus, and lateral habenular nucleus, and specific brainstem structures such as the pedunculopontine nucleus, and the raphe nucleus, are key components in regulating the reward circuit. Connectivity between these areas forms a complex neural network that mediates different aspects of reward processing. Advances in neuroimaging techniques allow better spatial and temporal resolution. These studies now demonstrate that human functional and structural imaging results map increasingly close to primate anatomy.},
  copyright = {2010 American College of Neuropsychopharmacology},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Neuropsychopharmacology2010\\Haber_Knutson_2010_The Reward Circuit.pdf}
}

@article{itoDistinctNeuralRepresentation2015,
  title = {Distinct {{Neural Representation}} in the {{Dorsolateral}}, {{Dorsomedial}}, and {{Ventral Parts}} of the {{Striatum}} during {{Fixed-}} and {{Free-Choice Tasks}}},
  author = {Ito, Makoto and Doya, Kenji},
  year = {2015},
  month = feb,
  journal = {Journal of Neuroscience},
  volume = {35},
  number = {8},
  pages = {3499--3514},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1962-14.2015},
  urldate = {2023-02-02},
  abstract = {The striatum is a major input site of the basal ganglia, which play an essential role in decision making. Previous studies have suggested that subareas of the striatum have distinct roles: the dorsolateral striatum (DLS) functions in habitual action, the dorsomedial striatum (DMS) in goal-directed actions, and the ventral striatum (VS) in motivation. To elucidate distinctive functions of subregions of the striatum in decision making, we systematically investigated information represented by phasically active neurons in DLS, DMS, and VS. Rats performed two types of choice tasks: fixed- and free-choice tasks. In both tasks, rats were required to perform nose poking to either the left or right hole after cue-tone presentation. A food pellet was delivered probabilistically depending on the presented cue and the selected action. The reward probability was fixed in fixed-choice task and varied in a block-wise manner in free-choice task. We found the following: (1) when rats began the tasks, a majority of VS neurons increased their firing rates and information regarding task type and state value was most strongly represented in VS; (2) during action selection, information of action and action values was most strongly represented in DMS; (3) action-command information (action representation before action selection) was stronger in the fixed-choice task than in the free-choice task in both DLS and DMS; and (4) action-command information was strongest in DLS, particularly when the same choice was repeated. We propose a hypothesis of hierarchical reinforcement learning in the basal ganglia to coherently explain these results.},
  chapter = {Articles},
  copyright = {Copyright \textcopyright{} 2015 the authors 0270-6474/15/353499-16\$15.00/0. This article is freely available online through the J Neurosci Author Open Choice option.},
  langid = {english},
  pmid = {25716849},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Journal of Neuroscience2015\\Ito_Doya_2015_Distinct Neural Representation in the Dorsolateral, Dorsomedial, and Ventral.pdf}
}

@article{kaplanDissociableRolesVentral2020,
  title = {Dissociable Roles of Ventral Pallidum Neurons in the Basal Ganglia Reinforcement Learning Network},
  author = {Kaplan, Alexander and {Mizrahi-Kliger}, Aviv D. and Israel, Zvi and Adler, Avital and Bergman, Hagai},
  year = {2020},
  month = apr,
  journal = {Nature Neuroscience},
  volume = {23},
  number = {4},
  pages = {556--564},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0605-y},
  urldate = {2023-03-13},
  abstract = {Reinforcement learning models treat the basal ganglia (BG) as an actor\textendash critic network. The ventral pallidum (VP) is a major component of the BG limbic system. However, its precise functional roles within the BG circuitry, particularly in comparison to the adjacent external segment of the globus pallidus (GPe), remain unexplored. We recorded the spiking activity of VP neurons, GPe cells (actor) and striatal cholinergic interneurons (critic) while monkeys performed a classical conditioning task. Here, we report that VP neurons can be classified into two distinct populations. The persistent population displayed sustained activation following visual cue presentation, was correlated with monkeys' behavior and showed uncorrelated spiking activity. The transient population displayed phasic synchronized responses that were correlated with the rate of learning and the reinforcement learning model's prediction error. Our results suggest that the VP is physiologically different from the GPe and identify the transient VP neurons as a BG critic.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature Neuroscience2020\\Kaplan et al_2020_Dissociable roles of ventral pallidum neurons in the basal ganglia.pdf}
}

@article{schultzRewardFunctionsBasal2016,
  title = {Reward Functions of the Basal Ganglia},
  author = {Schultz, Wolfram},
  year = {2016},
  month = jul,
  journal = {Journal of Neural Transmission},
  volume = {123},
  number = {7},
  pages = {679--693},
  issn = {1435-1463},
  doi = {10.1007/s00702-016-1510-0},
  urldate = {2023-01-20},
  abstract = {Besides their fundamental movement function evidenced by Parkinsonian deficits, the basal ganglia are involved in processing closely linked non-motor, cognitive and reward information. This review describes the reward functions of three brain structures that are major components of the basal ganglia or are closely associated with the basal ganglia, namely midbrain dopamine neurons, pedunculopontine nucleus, and striatum (caudate nucleus, putamen, nucleus accumbens). Rewards are involved in learning (positive reinforcement), approach behavior, economic choices and positive emotions. The response of dopamine neurons to rewards consists of an early detection component and a subsequent reward component that reflects a prediction error in economic utility, but is unrelated to movement. Dopamine activations to non-rewarded or aversive stimuli reflect physical impact, but not punishment. Neurons in pedunculopontine nucleus project their axons to dopamine neurons and process sensory stimuli, movements and rewards and reward-predicting stimuli without coding outright reward prediction errors. Neurons in striatum, besides their pronounced movement relationships, process rewards irrespective of sensory and motor aspects, integrate reward information into movement activity, code the reward value of individual actions, change their reward-related activity during learning, and code own reward in social situations depending on whose action produces the reward. These data demonstrate a variety of well-characterized reward processes in specific basal ganglia nuclei consistent with an important function in non-motor aspects of motivated behavior.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Journal of Neural Transmission2016\\Schultz_2016_Reward functions of the basal ganglia.pdf}
}

@article{marchantLateralHypothalamusRequired2009,
  title = {Lateral {{Hypothalamus Is Required}} for {{Context-Induced Reinstatement}} of {{Extinguished Reward Seeking}}},
  author = {Marchant, Nathan J. and Hamlin, Adam S. and McNally, Gavan P.},
  year = {2009},
  month = feb,
  journal = {Journal of Neuroscience},
  volume = {29},
  number = {5},
  pages = {1331--1342},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.5194-08.2009},
  urldate = {2023-03-14},
  abstract = {We studied the role of lateral hypothalamus (LH) in context-induced reinstatement (renewal) of reward seeking. Rats were trained to respond for 4\% (v/v) alcoholic beer or 10\% (w/v) sucrose reward in one context (Context A) before extinction training in a second context (Context B). On test, rats were returned to the training context, A (ABA), or the extinction context, B (ABB). Return to the training context (ABA) produced robust reinstatement. Reversible inactivation of LH via baclofen/muscimol infusion prevented context-induced reinstatement of beer and sucrose seeking. This prevention was specific to bilateral infusions into LH. We then used the retrograde neuronal tracer cholera toxin b subunit (CTb) combined with detection of the c-Fos protein to identify activated afferents to LH during context-induced reinstatement of beer seeking. Double labeling for c-Fos and CTb revealed a significant recruitment of LH-projecting neurons in nucleus accumbens shell (AcbSh) during reinstatement. These afferents could be classified into two anatomically and functionally distinct groups. First, afferents in the ventral AcbSh projecting to LH were activated during reinstatement. Second, afferents in the dorsomedial AcbSh projecting to LH were activated during test in the extinction context. These recruitments were specific to an AcbSh\textendash LH pathway because they were not observed following CTb injection into the immediately adjacent perifornical hypothalamus. These results show that LH is critical for context-induced reinstatement of reward seeking and that parallel striatal-hypothalamic pathways are recruited following return to the training versus extinction contexts.},
  chapter = {Articles},
  copyright = {Copyright \textcopyright{} 2009 Society for Neuroscience 0270-6474/09/291331-12\$15.00/0},
  langid = {english},
  pmid = {19193880},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Journal of Neuroscience\\2009\\Marchant et al_2009_Lateral Hypothalamus Is Required for Context-Induced Reinstatement of.pdf}
}

@article{berridgePleasureSystemsBrain2015,
  title = {Pleasure {{Systems}} in the {{Brain}}},
  author = {Berridge, Kent C. and Kringelbach, Morten L.},
  year = {2015},
  month = may,
  journal = {Neuron},
  volume = {86},
  number = {3},
  pages = {646--664},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2015.02.018},
  urldate = {2022-10-29},
  abstract = {Pleasure is mediated by well-developed mesocorticolimbic circuitry and serves adaptive functions. In affective disorders, anhedonia (lack of pleasure) or dysphoria (negative affect) can result from breakdowns of that hedonic system. Human neuroimaging studies indicate that surprisingly similar circuitry is activated by quite diverse pleasures, suggesting a common neural currency shared by all. Wanting for reward is generated by a large and distributed brain system. Liking, or pleasure itself, is generated by a smaller set of hedonic hot spots within limbic circuitry. Those hot spots also can be embedded in broader anatomical patterns of valence organization, such as in a keyboard pattern of nucleus accumbens generators for desire versus dread. In contrast, some of the best known textbook candidates for pleasure generators, including classic pleasure electrodes and the mesolimbic dopamine system, may not generate pleasure after all. These emerging insights into brain pleasure mechanisms may eventually facilitate better treatments for affective disorders.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Neuron2015\\Berridge_Kringelbach_2015_Pleasure Systems in the Brain.pdf}
}

@misc{biorender2017,
  title = {{{BioRender}}},
  author = {{BioRender}},
  year = {2017}
}

@article{berridgeAffectiveNeurosciencePleasure2008,
  title = {Affective Neuroscience of Pleasure: Reward in Humans and Animals},
  shorttitle = {Affective Neuroscience of Pleasure},
  author = {Berridge, Kent C. and Kringelbach, Morten L.},
  year = {2008},
  month = aug,
  journal = {Psychopharmacology},
  volume = {199},
  number = {3},
  pages = {457--480},
  issn = {1432-2072},
  doi = {10.1007/s00213-008-1099-6},
  urldate = {2022-10-29},
  abstract = {Pleasure and reward are generated by brain circuits that are largely shared between humans and other animals.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Psychopharmacology2008\\Berridge_Kringelbach_2008_Affective neuroscience of pleasure.pdf}
}

@article{goodDynamicsMolecularEvolution2017,
  title = {The Dynamics of Molecular Evolution over 60,000 Generations},
  author = {Good, Benjamin H. and McDonald, Michael J. and Barrick, Jeffrey E. and Lenski, Richard E. and Desai, Michael M.},
  year = {2017},
  month = nov,
  journal = {Nature},
  volume = {551},
  number = {7678},
  pages = {45--50},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature24287},
  urldate = {2023-02-26},
  abstract = {The outcomes of evolution are determined by a stochastic dynamical process that governs how mutations arise and spread through a population. However, it is difficult to observe these dynamics directly over long periods and across entire genomes. Here we analyse the dynamics of molecular evolution in twelve experimental populations of Escherichia coli, using whole-genome metagenomic sequencing at five hundred-generation intervals through sixty thousand generations. Although the rate of fitness gain declines over time, molecular evolution is characterized by signatures of rapid adaptation throughout the duration of the experiment, with multiple beneficial variants simultaneously competing for dominance in each population. Interactions between ecological and evolutionary processes play an important role, as long-term quasi-stable coexistence arises spontaneously in most populations, and evolution continues within each clade. We also present evidence that the targets of natural selection change over time, as epistasis and historical contingency alter the strength of selection on different genes. Together, these results show that long-term adaptation to a constant environment can be a more complex and dynamic process than is often assumed.},
  copyright = {2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Nature2017\\Good et al_2017_The dynamics of molecular evolution over 60,000 generations.pdf}
}

@article{dearaujoRethinkingFoodReward2020,
  title = {Rethinking {{Food Reward}}},
  author = {{de Araujo}, Ivan E. and Schatzker, Mark and Small, Dana M.},
  year = {2020},
  journal = {Annual Review of Psychology},
  volume = {71},
  number = {1},
  pages = {139--164},
  doi = {10.1146/annurev-psych-122216-011643},
  urldate = {2023-01-20},
  abstract = {The conscious perception of the hedonic sensory properties of caloric foods is commonly believed to guide our dietary choices. Current and traditional models implicate the consciously perceived hedonic qualities of food as driving overeating, whereas subliminal signals arising from the gut would curb our uncontrolled desire for calories. Here we review recent animal and human studies that support a markedly different model for food reward. These findings reveal in particular the existence of subcortical body-to-brain neural pathways linking gastrointestinal nutrient sensors to the brain's reward regions. Unexpectedly, consciously perceptible hedonic qualities appear to play a less relevant, and mostly transient, role in food reinforcement. In this model, gut-brain reward pathways bypass cranial taste and aroma sensory receptors and the cortical networks that give rise to flavor perception. They instead reinforce behaviors independently of the cognitive processes that support overt insights into the nature of our dietary decisions.},
  pmid = {31561741},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Annual Review of Psychology2020\\de Araujo et al_2020_Rethinking Food Reward.pdf}
}

@article{dunlopRoleDopaminePathophysiology2007,
  title = {The {{Role}} of {{Dopamine}} in the {{Pathophysiology}} of {{Depression}}},
  author = {Dunlop, Boadie W. and Nemeroff, Charles B.},
  year = {2007},
  month = mar,
  journal = {Archives of General Psychiatry},
  volume = {64},
  number = {3},
  pages = {327--337},
  issn = {0003-990X},
  doi = {10.1001/archpsyc.64.3.327},
  urldate = {2023-03-07},
  abstract = {Multiple sources of evidence support a role for diminished dopaminergic neurotransmission in major depression. The physiological alterations underlying reduced dopamine (DA) signaling could result from either diminished DA release from presynaptic neurons or impaired signal transduction, either due to changes in receptor number or function and/or altered intracellular signal processing. There are data supporting each of these mechanisms, although interpretation of previous research is confounded by issues around study population, medication status, and technological limitations. In some patients with depression, DA-related disturbances improve by treatment with antidepressants, presumably by acting on serotonergic or noradrenergic circuits, which then affect DA function. However, most antidepressant treatments do not directly enhance DA neurotransmission, which may contribute to residual symptoms, including impaired motivation, concentration, and pleasure. Animal models of major depression show considerable responsiveness to manipulations of DA neurotransmission. Several studies, including postmortem investigations, particularly of subjects with severe depression, have demonstrated reduced concentrations of DA metabolites both in the cerebrospinal fluid and in brain regions that mediate mood and motivation. Although the neuroimaging findings are not unequivocal, several studies support the hypothesis that major depression is associated with a state of reduced DA transmission, possibly reflected by a compensatory up-regulation of D2 receptors. These alterations in DA signaling may underlie the findings of increased ``liking'' or ``high'' feelings reported by severely depressed subjects treated with d-amphetamine compared with the response of less severely ill and normal control subjects. The efficacy of medications that directly act on DA neurons or receptors, such as monoamine oxidase inhibitors and pramipexole, suggests that subtypes of depression stemming from a primary DA dysfunction exist. Further research on the contribution of DA to the pathophysiology of depression is justified to improve outcomes for patients with treatment-resistant and nonremitting depression.}
}

@article{solinasDopamineAddictionWhat2019,
  title = {Dopamine and Addiction: What Have We Learned from 40~Years of Research},
  shorttitle = {Dopamine and Addiction},
  author = {Solinas, Marcello and Belujon, Pauline and Fernagut, Pierre Olivier and Jaber, Mohamed and Thiriet, Nathalie},
  year = {2019},
  month = apr,
  journal = {Journal of Neural Transmission},
  volume = {126},
  number = {4},
  pages = {481--516},
  issn = {1435-1463},
  doi = {10.1007/s00702-018-1957-2},
  urldate = {2023-03-07},
  abstract = {Among the neurotransmitters involved in addiction, dopamine (DA) is clearly the best known. The critical role of DA in addiction is supported by converging evidence that has been accumulated in the last 40 years. In the present review, first we describe the dopaminergic system in terms of connectivity, functioning and involvement in reward processes. Second, we describe the functional, structural, and molecular changes induced by drugs within the DA system in terms of neuronal activity, synaptic plasticity and transcriptional and molecular adaptations. Third, we describe how genetic mouse models have helped characterizing the role of DA in addiction. Fourth, we describe the involvement of the DA system in the vulnerability to addiction and the interesting case of addiction DA replacement therapy in Parkinson's disease. Finally, we describe how the DA system has been targeted to treat patients suffering from addiction and the result obtained in clinical settings and we discuss how these different lines of evidence have been instrumental in shaping our understanding of the physiopathology of drug addiction.},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Journal of Neural Transmission2019\\Solinas et al_2019_Dopamine and addiction.pdf}
}

@article{koobNeuroscienceAddiction1998,
  title = {Neuroscience of {{Addiction}}},
  author = {Koob, George F and Sanna, Pietro Paolo and Bloom, Floyd E},
  year = {1998},
  month = sep,
  journal = {Neuron},
  volume = {21},
  number = {3},
  pages = {467--476},
  issn = {08966273},
  doi = {10.1016/S0896-6273(00)80557-7},
  urldate = {2022-12-27},
  langid = {english},
  file = {C\:\\Users\\Yuji-Kanagawa\\Zotero\\storage\\LUVWXVDN\\Koob et al. - 1998 - Neuroscience of Addiction.pdf}
}

@article{schultzNeuronalRewardDecision2015,
  title = {Neuronal {{Reward}} and {{Decision Signals}}: {{From Theories}} to {{Data}}},
  shorttitle = {Neuronal {{Reward}} and {{Decision Signals}}},
  author = {Schultz, Wolfram},
  year = {2015},
  month = jul,
  journal = {Physiological Reviews},
  volume = {95},
  number = {3},
  pages = {853--951},
  publisher = {{American Physiological Society}},
  issn = {0031-9333},
  doi = {10.1152/physrev.00023.2014},
  urldate = {2022-04-29},
  abstract = {Rewards are crucial objects that induce learning, approach behavior, choices, and emotions. Whereas emotions are difficult to investigate in animals, the learning function is mediated by neuronal reward prediction error signals which implement basic constructs of reinforcement learning theory. These signals are found in dopamine neurons, which emit a global reward signal to striatum and frontal cortex, and in specific neurons in striatum, amygdala, and frontal cortex projecting to select neuronal populations. The approach and choice functions involve subjective value, which is objectively assessed by behavioral choices eliciting internal, subjective reward preferences. Utility is the formal mathematical characterization of subjective value and a prime decision variable in economic choice theory. It is coded as utility prediction error by phasic dopamine responses. Utility can incorporate various influences, including risk, delay, effort, and social interaction. Appropriate for formal decision mechanisms, rewards are coded as object value, action value, difference value, and chosen value by specific neurons. Although all reward, reinforcement, and decision variables are theoretical constructs, their neuronal signals constitute measurable physical implementations and as such confirm the validity of these concepts. The neuronal reward signals provide guidance for behavior while constraining the free will to act.},
  file = {C\:\\Users\\Yuji-Kanagawa\\Dropbox\\Zotero\\Physiological Reviews2015\\Schultz_2015_Neuronal Reward and Decision Signals.pdf}
}
